{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMcxufce3Esk07wvTdrFX0J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aknip/Langchain-etc./blob/main/Langchain-Agent-Insurance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Langchain Agent Insurance - using OpenAI functions\n",
        "\n",
        "Different agents and code implementations how to run Langchain agents using OpenAI functions: Single prompt, chat with memory, from command line or in Gradio web app, using AgentExecutor or your own custom loop.\n",
        "\n",
        "## How to use\n",
        "1. Run all cells of group \"Basic setup for all agents, tools and apps\"\n",
        "2. Run one of the two agent/tool groups\n",
        "3. Run different code implementations after that: CLI, Gradio, custom loops...\n",
        "\n",
        "For more information see https://levelup.gitconnected.com/building-a-powerful-agent-has-no-challenge-today-774e27be818d"
      ],
      "metadata": {
        "id": "_yJpe7D-EXzF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic setup for all agents, tools and apps"
      ],
      "metadata": {
        "id": "gOMfnUf3_oTj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "from getpass import getpass\n",
        "import psutil\n",
        "IN_NOTEBOOK = any([\"jupyter-notebook\" in i for i in psutil.Process().parent().cmdline()])\n",
        "if IN_NOTEBOOK:\n",
        "  CREDS = json.loads(getpass(\"Secrets (JSON string): \"))\n",
        "  os.environ['CREDS'] = json.dumps(CREDS)\n",
        "  CREDS = json.loads(os.getenv('CREDS'))"
      ],
      "metadata": {
        "id": "IWrCvpKaENeu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afIkZ1hD4RYB"
      },
      "outputs": [],
      "source": [
        "!pip install langchain==0.0.311 langchain-experimental==0.0.27 langchainhub==0.1.13 google-search-results==2.4.2 wikipedia==1.4.0 openai==0.28.1 gradio==3.47.1 -q\n",
        "%load_ext gradio\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import Tool, AgentExecutor\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain import hub\n",
        "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain.utilities import SerpAPIWrapper, SQLDatabase, WikipediaAPIWrapper\n",
        "from langchain_experimental.sql import SQLDatabaseChain\n",
        "from langchain.tools import WikipediaQueryRun\n",
        "from langchain.agents.format_scratchpad import format_to_openai_functions\n",
        "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
        "from langchain.tools.render import format_tool_to_openai_function\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain.tools import BaseTool, StructuredTool\n",
        "from langchain.schema.agent import AgentFinish\n",
        "from langchain.schema import BaseMessage, AIMessage, HumanMessage\n",
        "import os\n",
        "import langchain\n",
        "import openai\n",
        "import textwrap\n",
        "import gradio as gr\n",
        "import random\n",
        "import time"
      ],
      "metadata": {
        "id": "CEhw8Ye15BgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agent 2: Calculate insurance premium"
      ],
      "metadata": {
        "id": "EoYqbRg0_w19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = CREDS['OpenAI']['v2']['credential']\n",
        "llm = ChatOpenAI(temperature=0, model='gpt-4-0613')\n",
        "\n",
        "def calculate_insurance_premium(insured_sum: int, industry: str, country: str = \"Germany\") -> float:\n",
        "    \"\"\"Calculate the premium for an insurance based on the maximum insured sum and the industry of the customer.\"\"\"\n",
        "    premium = insured_sum*0.25\n",
        "    result = str(premium) + \" (for \" + country + \")\"\n",
        "    return result\n",
        "\n",
        "calc_tool = StructuredTool.from_function(calculate_insurance_premium, return_direct=False)\n",
        "\n",
        "def show_history() -> str:\n",
        "    \"\"\"Show the history of the chat or conversation to the user.\"\"\"\n",
        "    chat_history_string = str(response[\"chat_history\"]).replace(\"), \", \")§§§ \")[1:-1]\n",
        "    chat_history = chat_history_string.split(\"§§§ \")\n",
        "    msg_history_string = \"\"\n",
        "    for chat_string in chat_history:\n",
        "      tmp = chat_string.split(\"(content='\")\n",
        "      msg_history_string = msg_history_string + tmp[0] + \" - \" + tmp[1][:-2] + \"\\n\"\n",
        "    return msg_history_string\n",
        "\n",
        "show_history_tool = StructuredTool.from_function(show_history, return_direct=True)\n",
        "\n",
        "tools = [calc_tool, show_history_tool]\n",
        "tools_as_openai_functions = [format_tool_to_openai_function(t) for t in tools]\n",
        "tools_dict = {\n",
        "    \"calculate_insurance_premium\": calc_tool,\n",
        "    \"show_history\": show_history_tool\n",
        "    }\n",
        "\n",
        "llm_with_tools = llm.bind(\n",
        "    functions=tools_as_openai_functions\n",
        ")\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a useful assistant.\"),\n",
        "    MessagesPlaceholder(variable_name='chat_history'),\n",
        "    (\"user\", \"{input}\"),\n",
        "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "])\n",
        "\n",
        "agent = {\n",
        "    \"input\": lambda x: x[\"input\"],\n",
        "    \"agent_scratchpad\": lambda x: format_to_openai_functions(x['intermediate_steps']),\n",
        "    \"chat_history\": lambda x: x[\"chat_history\"]\n",
        "} | prompt | llm_with_tools | OpenAIFunctionsAgentOutputParser()\n"
      ],
      "metadata": {
        "id": "vAzSbqz7_0_U"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# show calc_tool as OpenAI function\n",
        "print(json.dumps(format_tool_to_openai_function(calc_tool), sort_keys=False, indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Gn4scosGVNK",
        "outputId": "bcea8102-849b-4501-a98b-483d126c14e1",
        "cellView": "form",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"name\": \"calculate_insurance_premium\",\n",
            "  \"description\": \"calculate_insurance_premium(insured_sum: int, industry: str, country: str = 'Germany') -> float - Calculate the premium for an insurance based on the maximum insured sum and the industry of the customer.\",\n",
            "  \"parameters\": {\n",
            "    \"title\": \"calculate_insurance_premiumSchemaSchema\",\n",
            "    \"type\": \"object\",\n",
            "    \"properties\": {\n",
            "      \"insured_sum\": {\n",
            "        \"title\": \"Insured Sum\",\n",
            "        \"type\": \"integer\"\n",
            "      },\n",
            "      \"industry\": {\n",
            "        \"title\": \"Industry\",\n",
            "        \"type\": \"string\"\n",
            "      },\n",
            "      \"country\": {\n",
            "        \"title\": \"Country\",\n",
            "        \"default\": \"Germany\",\n",
            "        \"type\": \"string\"\n",
            "      }\n",
            "    },\n",
            "    \"required\": [\n",
            "      \"insured_sum\",\n",
            "      \"industry\"\n",
            "    ]\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "demoSchema = {\n",
        "  \"name\": \"calculate_insurance_premium\",\n",
        "  \"description\": \"calculate_insurance_premium(insured_sum: int, industry: str, country: str = 'Germany') -> float - Calculate the premium for an insurance based on the maximum insured sum and the industry of the customer.\",\n",
        "  \"parameters\": {\n",
        "    \"title\": \"calculate_insurance_premiumSchemaSchema\",\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\n",
        "      \"insured_sum\": {\n",
        "        \"title\": \"Insured Sum\",\n",
        "        \"type\": \"integer\"\n",
        "      },\n",
        "      \"industry\": {\n",
        "        \"title\": \"Industry\",\n",
        "        \"type\": \"string\"\n",
        "      },\n",
        "      \"country\": {\n",
        "        \"title\": \"Country\",\n",
        "        \"default\": \"Germany\",\n",
        "        \"type\": \"string\",\n",
        "        \"enum\": [\"positive\", \"negative\"],\n",
        "        \"description\": \"The Country where the insured company is located\"\n",
        "      }\n",
        "    },\n",
        "    \"required\": [\n",
        "      \"insured_sum\",\n",
        "      \"industry\"\n",
        "    ]\n",
        "  }\n",
        "}"
      ],
      "metadata": {
        "id": "AFRanByCQJAW",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chat loop"
      ],
      "metadata": {
        "id": "-fL3b1FXIx9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "langchain.debug = False\n",
        "\n",
        "intermediate_steps = []\n",
        "chat_history = []\n",
        "\n",
        "# manual loop / like AgentExecutor\n",
        "def chat_manual_loop(prompt_text: str) -> str:\n",
        "  while True:\n",
        "      output = agent.invoke({\n",
        "          \"input\": prompt_text,\n",
        "          \"intermediate_steps\": intermediate_steps,\n",
        "          \"chat_history\": chat_history\n",
        "      })\n",
        "      if isinstance(output, AgentFinish):\n",
        "          final_result = output.return_values[\"output\"]\n",
        "          chat_history.append(HumanMessage(content=(prompt_text)))\n",
        "          chat_history.append(AIMessage(content=(output.return_values[\"output\"])))\n",
        "          break\n",
        "      else:\n",
        "          print(output.tool, output.tool_input)\n",
        "          tool = tools_dict[output.tool]\n",
        "          observation = tool.run(output.tool_input)\n",
        "          intermediate_steps.append((output, observation))\n",
        "  return final_result\n",
        "\n",
        "chat_response = chat_manual_loop(\"Kalkuliere die Versicherungsprämie für eine Versicherungssumme von 10000000\")\n",
        "print(chat_response)"
      ],
      "metadata": {
        "id": "XXmSApHfCAZw",
        "outputId": "200bcd11-e047-468d-f95a-be6d25b9879f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Natürlich, ich kann das für Sie berechnen. Könnten Sie mir bitte noch mitteilen, in welcher Branche Sie tätig sind?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_response = chat_manual_loop(\"Die Branche ist Metallbau.\")\n",
        "print(chat_response)"
      ],
      "metadata": {
        "id": "vyPfeoPPCjoU",
        "outputId": "f571cf86-815f-42b4-e7a4-0d2a74049a80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Die Versicherungsprämie für eine Versicherungssumme von 10.000.000 € in der Branche Metallbau beträgt in Deutschland 2.500.000 €.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_response = chat_manual_loop(\"Zeige mir meine letzten Nachrichten.\")\n",
        "print(chat_response)"
      ],
      "metadata": {
        "id": "S8MLl2hZCtuP",
        "outputId": "1d049483-260b-4636-b49e-5e19d4ba0ee9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "show_history {}\n",
            "Hier sind Ihre letzten Nachrichten:\n",
            "\n",
            "1. Sie: \"Kalkuliere die Versicherungsprämie für eine Versicherungssumme von 10000000\"\n",
            "2. Ich: \"Natürlich, ich kann das für Sie berechnen. Könnten Sie mir bitte noch mitteilen, in welcher Branche Sie tätig sind?\"\n",
            "3. Sie: \"Die Branche ist Metallbau.\"\n",
            "4. Ich: \"Die Versicherungsprämie für eine Versicherungssumme von 10.000.000 € in der Branche Metallbau beträgt in Deutschland 2.500.000 €.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, memory=memory)\n",
        "messages = [{\"role\": \"assistant\", \"content\": \"How can I help you?\"}]\n",
        "langchain.debug = False"
      ],
      "metadata": {
        "id": "qVfrjxhuUbn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prompt = \"Give me the premium for an insured sum of 10000000\"\n",
        "#prompt = \"The industry is chemical production\"\n",
        "prompt = \"Show me my last messages\"\n",
        "messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "print(\"user: \" + prompt)\n",
        "response = agent_executor.invoke({\"input\": prompt})\n",
        "msg = {\"role\": \"assistant\", \"content\": response[\"output\"]}\n",
        "messages.append(msg)\n",
        "print(textwrap.fill(\"assistant: \" + response[\"output\"], 80))\n",
        "print(\"\\nHistory:\")\n",
        "for msg in messages:\n",
        "    #st.chat_message(msg[\"role\"]).write(msg[\"content\"])\n",
        "    print(textwrap.fill(msg[\"role\"] + \": \" + msg[\"content\"], 80))"
      ],
      "metadata": {
        "id": "OjDvg8GSaSP8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "622374d9-1120-4897-e04c-1f80742b32c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user: Show me my last messages\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `show_history` with `{}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[33;1m\u001b[1;3mHumanMessage - Give me the premium for an insured sum of 10000000\n",
            "AIMessage - Sure, I can help with that. However, I also need to know the industry of the customer to calculate the insurance premium. Could you please provide that information?\n",
            "HumanMessage - The industry is chemical production\n",
            "AIMessage - The premium for an insured sum of 10,000,000 in the chemical production industry in Germany is 2,500,000.\n",
            "HumanMessage - Show me my last messages\n",
            "AIMessage - HumanMessage - Give me the premium for an insured sum of 10000000\\nAIMessage - Sure, I can help with that. However, I also need to know the industry of the customer to calculate the insurance premium. Could you please provide that information?\\nHumanMessage - The industry is chemical production\\nAIMessage - The premium for an insured sum of 10,000,000 in the chemical production industry in Germany is 2,500,000.\\n\n",
            "\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "assistant: HumanMessage - Give me the premium for an insured sum of 10000000\n",
            "AIMessage - Sure, I can help with that. However, I also need to know the\n",
            "industry of the customer to calculate the insurance premium. Could you please\n",
            "provide that information? HumanMessage - The industry is chemical production\n",
            "AIMessage - The premium for an insured sum of 10,000,000 in the chemical\n",
            "production industry in Germany is 2,500,000. HumanMessage - Show me my last\n",
            "messages AIMessage - HumanMessage - Give me the premium for an insured sum of\n",
            "10000000\\nAIMessage - Sure, I can help with that. However, I also need to know\n",
            "the industry of the customer to calculate the insurance premium. Could you\n",
            "please provide that information?\\nHumanMessage - The industry is chemical\n",
            "production\\nAIMessage - The premium for an insured sum of 10,000,000 in the\n",
            "chemical production industry in Germany is 2,500,000.\\n\n",
            "\n",
            "History:\n",
            "assistant: How can I help you?\n",
            "user: Give me the premium for an insured sum of 10000000\n",
            "assistant: Sure, I can help with that. However, I also need to know the industry\n",
            "of the customer to calculate the insurance premium. Could you please provide\n",
            "that information?\n",
            "user: The industry is chemical production\n",
            "assistant: The premium for an insured sum of 10,000,000 in the chemical\n",
            "production industry in Germany is 2,500,000.\n",
            "user: Show me my last messages\n",
            "assistant: HumanMessage - Give me the premium for an insured sum of 10000000\n",
            "AIMessage - Sure, I can help with that. However, I also need to know the\n",
            "industry of the customer to calculate the insurance premium. Could you please\n",
            "provide that information? HumanMessage - The industry is chemical production\n",
            "AIMessage - The premium for an insured sum of 10,000,000 in the chemical\n",
            "production industry in Germany is 2,500,000.\n",
            "user: Show me my last messages\n",
            "assistant: HumanMessage - Give me the premium for an insured sum of 10000000\n",
            "AIMessage - Sure, I can help with that. However, I also need to know the\n",
            "industry of the customer to calculate the insurance premium. Could you please\n",
            "provide that information? HumanMessage - The industry is chemical production\n",
            "AIMessage - The premium for an insured sum of 10,000,000 in the chemical\n",
            "production industry in Germany is 2,500,000. HumanMessage - Show me my last\n",
            "messages AIMessage - HumanMessage - Give me the premium for an insured sum of\n",
            "10000000\\nAIMessage - Sure, I can help with that. However, I also need to know\n",
            "the industry of the customer to calculate the insurance premium. Could you\n",
            "please provide that information?\\nHumanMessage - The industry is chemical\n",
            "production\\nAIMessage - The premium for an insured sum of 10,000,000 in the\n",
            "chemical production industry in Germany is 2,500,000.\\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show_history()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "Yvmgw3wYgAvo",
        "outputId": "b73b578e-67b7-4ec5-d05c-f6a82353ae63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'HumanMessage - Give me the premium for an insured sum of 10000000\\nAIMessage - Sure, I can help with that. However, I also need to know the industry of the customer to calculate the insurance premium. Could you please provide that information?\\nHumanMessage - The industry is chemical production\\nAIMessage - The premium for an insurance with an insured sum of 10,000,000 in the chemical production industry in Germany is 2,500,000.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Memory from response object:\")\n",
        "chat_history_string = str(response[\"chat_history\"]).replace(\"), \", \")§§§ \")[1:-1]\n",
        "chat_history = chat_history_string.split(\"§§§ \")\n",
        "msg_history = []\n",
        "for chat_string in chat_history:\n",
        "  tmp = chat_string.split(\"(content='\")\n",
        "  msg_history.append({\"role\": tmp[0], \"content\": tmp[1][:-2]})\n",
        "#for msg in msg_history:\n",
        "#  print(msg)\n",
        "print('\\n'.join(str(x) for x in msg_history))"
      ],
      "metadata": {
        "id": "ZmCuWwuijWDD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27a971bd-8ef8-4047-c4ed-a69d911f7dc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory from response object:\n",
            "{'role': 'HumanMessage', 'content': 'Give me the premium for an insured sum of 10000000'}\n",
            "{'role': 'AIMessage', 'content': 'Sure, I can help with that. However, I also need to know the industry of the customer to calculate the insurance premium. Could you please provide that information?'}\n",
            "{'role': 'HumanMessage', 'content': 'The industry is chemical production'}\n",
            "{'role': 'AIMessage', 'content': 'The premium for an insured sum of 10,000,000 in the chemical production industry in Germany is 2,500,000.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradio Chat App for Agent"
      ],
      "metadata": {
        "id": "O_jGi0yQ-sEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Init agent and memory\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, memory=memory)\n",
        "messages = [{\"role\": \"assistant\", \"content\": \"How can I help you?\"}]\n",
        "\n",
        "#\n",
        "# Gradio app\n",
        "#\n",
        "\n",
        "# Theming\n",
        "theme = gr.themes.Default(\n",
        "    primary_hue=\"slate\" # , radius_size=gr.themes.Size(radius_sm=\"3px\", radius_xs=\"2px\", radius_xxs=\"1px\")\n",
        ")\n",
        "# Styling: Change max width\n",
        "css = \"\"\"\n",
        "  .gradio-container {max-width: 800px!important}\n",
        "  .vspacer1 {margin-top: 20px}\n",
        "\"\"\"\n",
        "\n",
        "with gr.Blocks(theme=theme, css=css) as demo:\n",
        "\n",
        "    gr.Markdown(\"# Agent Chat\", elem_classes=\"vspacer1\")\n",
        "\n",
        "    with gr.Tab(\"Chat\"):\n",
        "      # https://www.gradio.app/docs/chatbot\n",
        "\n",
        "      chatbot = gr.Chatbot(bubble_full_width=False)\n",
        "      msg = gr.Textbox()\n",
        "      clear = gr.ClearButton([msg, chatbot])\n",
        "\n",
        "      def ask(message, chat_history):\n",
        "          chat_history.append((message, None))\n",
        "          messages.append({\"role\": \"user\", \"content\": message})\n",
        "          return \"\", chat_history\n",
        "\n",
        "      def respond(chat_history):\n",
        "          prompt = chat_history[-1][0] # get prompt from history (last entry)\n",
        "          response = agent_executor.invoke({\"input\": prompt})\n",
        "          msg = {\"role\": \"assistant\", \"content\": response[\"output\"]}\n",
        "          messages.append(msg)\n",
        "          chat_history.append((None, response[\"output\"]))\n",
        "          print(\"\\n\\nMemory from response object:\")\n",
        "          print(textwrap.fill(str(response[\"chat_history\"]), 80))\n",
        "          return chat_history\n",
        "\n",
        "      msg.submit(ask, [msg, chatbot], [msg, chatbot], queue=False).then(\n",
        "        respond, chatbot, chatbot\n",
        "      )\n",
        "\n",
        "demo.launch(quiet=True, share=False, debug=True)"
      ],
      "metadata": {
        "id": "kioXkMb2-vUX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
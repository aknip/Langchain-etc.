{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOUW6WcSlHTqNgx7IWYNriu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aknip/Langchain-etc./blob/main/Langchain-Agent-Insurance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Langchain Agent Insurance - using OpenAI functions\n",
        "\n",
        "Different agents and code implementations how to run Langchain agents using OpenAI functions: Single prompt, chat with memory, from command line or in Gradio web app, using AgentExecutor or your own custom loop.\n",
        "\n",
        "## How to use\n",
        "1. Run all cells of group \"Basic setup for all agents, tools and apps\"\n",
        "2. Run one of the two agent/tool groups\n",
        "3. Run different code implementations after that: CLI, Gradio, custom loops...\n",
        "\n",
        "For more information see https://levelup.gitconnected.com/building-a-powerful-agent-has-no-challenge-today-774e27be818d"
      ],
      "metadata": {
        "id": "_yJpe7D-EXzF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic setup for all agents, tools and apps"
      ],
      "metadata": {
        "id": "gOMfnUf3_oTj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "from getpass import getpass\n",
        "import psutil\n",
        "IN_NOTEBOOK = any([\"jupyter-notebook\" in i for i in psutil.Process().parent().cmdline()])\n",
        "if IN_NOTEBOOK:\n",
        "  CREDS = json.loads(getpass(\"Secrets (JSON string): \"))\n",
        "  os.environ['CREDS'] = json.dumps(CREDS)\n",
        "  CREDS = json.loads(os.getenv('CREDS'))"
      ],
      "metadata": {
        "id": "IWrCvpKaENeu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afIkZ1hD4RYB"
      },
      "outputs": [],
      "source": [
        "!pip install langchain==0.0.311 langchain-experimental==0.0.27 langchainhub==0.1.13 google-search-results==2.4.2 wikipedia==1.4.0 openai==0.28.1 gradio==3.47.1 -q\n",
        "%load_ext gradio\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import Tool, AgentExecutor\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain import hub\n",
        "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain.utilities import SerpAPIWrapper, SQLDatabase, WikipediaAPIWrapper\n",
        "from langchain_experimental.sql import SQLDatabaseChain\n",
        "from langchain.tools import WikipediaQueryRun\n",
        "from langchain.agents.format_scratchpad import format_to_openai_functions\n",
        "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
        "from langchain.tools.render import format_tool_to_openai_function\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain.tools import BaseTool, StructuredTool\n",
        "from langchain.schema.agent import AgentFinish\n",
        "from langchain.schema import BaseMessage, AIMessage, HumanMessage\n",
        "import os\n",
        "import langchain\n",
        "import openai\n",
        "import textwrap\n",
        "import gradio as gr\n",
        "import random\n",
        "import time"
      ],
      "metadata": {
        "id": "CEhw8Ye15BgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agent 2: Calculate insurance premium"
      ],
      "metadata": {
        "id": "EoYqbRg0_w19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = CREDS['OpenAI']['v2']['credential']\n",
        "llm = ChatOpenAI(temperature=0, model='gpt-4-0613')\n",
        "\n",
        "def calculate_insurance_premium(insured_sum: int, currency: str, industry: str, customer: str = \"\", country: str = \"Germany\") -> float:\n",
        "    \"\"\"\n",
        "    Calculate the premium for an insurance based on the maximum insured sum and the industry of the customer.\n",
        "    Examples:\n",
        "    - Calculate the premium for an insured sum of 20000000 EUR, industry is construcion, customer \"Miller Ltd.\"\n",
        "    - Calculate an offer for Bayer AG, chemical industriy, insured sum 1000000 USD\n",
        "    - Give me a premium for chemical industriy, sum 1000000 M$\n",
        "    - Give me an offer for contruction industry and 20000000 TEUR insured sum\n",
        "    - Calculate with insured sum 10000000 EUR\n",
        "    \"\"\"\n",
        "    premium = insured_sum*0.25\n",
        "    result = str(premium) + \" (for \" + country + \")\"\n",
        "    return result\n",
        "\n",
        "calc_tool = StructuredTool.from_function(calculate_insurance_premium, return_direct=False)\n",
        "\n",
        "def show_calculation_history() -> str:\n",
        "    \"\"\"\n",
        "    Show the history of all calcuations to the user. Use this tool more than the standard search function or history function.\n",
        "    Examples:\n",
        "    - Show me the history of my calculations\n",
        "    - Show me all my offers\n",
        "    \"\"\"\n",
        "    chat_history_string = str(chat_history).replace(\"), \", \")§§§ \")[1:-1]\n",
        "    chat_history_array = chat_history_string.split(\"§§§ \")\n",
        "    msg_history_string = \"\"\n",
        "    for chat_string in chat_history_array:\n",
        "      tmp = chat_string.split(\"(content='\")\n",
        "      msg_history_string = msg_history_string + tmp[0] + \" - \" + tmp[1][:-2] + \"\\n\"\n",
        "    return msg_history_string\n",
        "\n",
        "show_calculation_history_tool = StructuredTool.from_function(show_calculation_history, return_direct=True)\n",
        "\n",
        "def show_hints() -> str:\n",
        "    \"\"\"\n",
        "    Show hints for using this agent. Use only these texts Use the same language as the answer before..\n",
        "    \"\"\"\n",
        "    hint = \"Hint: Ask 'Show me all customer names and premiums, use CSV format and ; as delimiter' \"\n",
        "    return hint\n",
        "\n",
        "show_hints_tool = StructuredTool.from_function(show_hints, return_direct=True)\n",
        "\n",
        "tools = [calc_tool, show_calculation_history_tool, show_hints_tool]\n",
        "tools_as_openai_functions = [format_tool_to_openai_function(t) for t in tools]\n",
        "tools_dict = {\n",
        "    \"calculate_insurance_premium\": calc_tool,\n",
        "    \"show_calculation_history\": show_calculation_history_tool,\n",
        "    \"show_hints\": show_hints_tool\n",
        "    }\n",
        "\n",
        "llm_with_tools = llm.bind(\n",
        "    functions=tools_as_openai_functions\n",
        ")\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a useful assistant.\"),\n",
        "    MessagesPlaceholder(variable_name='chat_history'),\n",
        "    (\"user\", \"{input}\"),\n",
        "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "])\n",
        "\n",
        "agent = {\n",
        "    \"input\": lambda x: x[\"input\"],\n",
        "    \"agent_scratchpad\": lambda x: format_to_openai_functions(x['intermediate_steps']),\n",
        "    \"chat_history\": lambda x: x[\"chat_history\"]\n",
        "} | prompt | llm_with_tools | OpenAIFunctionsAgentOutputParser()\n"
      ],
      "metadata": {
        "id": "vAzSbqz7_0_U"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# show calc_tool as OpenAI function\n",
        "print(json.dumps(format_tool_to_openai_function(calc_tool), sort_keys=False, indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Gn4scosGVNK",
        "outputId": "bcea8102-849b-4501-a98b-483d126c14e1",
        "cellView": "form",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"name\": \"calculate_insurance_premium\",\n",
            "  \"description\": \"calculate_insurance_premium(insured_sum: int, industry: str, country: str = 'Germany') -> float - Calculate the premium for an insurance based on the maximum insured sum and the industry of the customer.\",\n",
            "  \"parameters\": {\n",
            "    \"title\": \"calculate_insurance_premiumSchemaSchema\",\n",
            "    \"type\": \"object\",\n",
            "    \"properties\": {\n",
            "      \"insured_sum\": {\n",
            "        \"title\": \"Insured Sum\",\n",
            "        \"type\": \"integer\"\n",
            "      },\n",
            "      \"industry\": {\n",
            "        \"title\": \"Industry\",\n",
            "        \"type\": \"string\"\n",
            "      },\n",
            "      \"country\": {\n",
            "        \"title\": \"Country\",\n",
            "        \"default\": \"Germany\",\n",
            "        \"type\": \"string\"\n",
            "      }\n",
            "    },\n",
            "    \"required\": [\n",
            "      \"insured_sum\",\n",
            "      \"industry\"\n",
            "    ]\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "demoSchema = {\n",
        "  \"name\": \"calculate_insurance_premium\",\n",
        "  \"description\": \"calculate_insurance_premium(insured_sum: int, industry: str, country: str = 'Germany') -> float - Calculate the premium for an insurance based on the maximum insured sum and the industry of the customer.\",\n",
        "  \"parameters\": {\n",
        "    \"title\": \"calculate_insurance_premiumSchemaSchema\",\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\n",
        "      \"insured_sum\": {\n",
        "        \"title\": \"Insured Sum\",\n",
        "        \"type\": \"integer\"\n",
        "      },\n",
        "      \"industry\": {\n",
        "        \"title\": \"Industry\",\n",
        "        \"type\": \"string\"\n",
        "      },\n",
        "      \"country\": {\n",
        "        \"title\": \"Country\",\n",
        "        \"default\": \"Germany\",\n",
        "        \"type\": \"string\",\n",
        "        \"enum\": [\"positive\", \"negative\"],\n",
        "        \"description\": \"The Country where the insured company is located\"\n",
        "      }\n",
        "    },\n",
        "    \"required\": [\n",
        "      \"insured_sum\",\n",
        "      \"industry\"\n",
        "    ]\n",
        "  }\n",
        "}"
      ],
      "metadata": {
        "id": "AFRanByCQJAW",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chat loop"
      ],
      "metadata": {
        "id": "-fL3b1FXIx9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "langchain.debug = False\n",
        "\n",
        "intermediate_steps = []\n",
        "chat_history = []\n",
        "\n",
        "block_memory = False\n",
        "\n",
        "# manual loop / like AgentExecutor\n",
        "def chat_manual_loop(prompt_text: str) -> str:\n",
        "  block_memory = False\n",
        "  while True:\n",
        "      output = agent.invoke({\n",
        "          \"input\": prompt_text + \"\\nGib anschliessend einen Tipp zur Nutzung dieses Agents aus.\",\n",
        "          \"intermediate_steps\": intermediate_steps,\n",
        "          \"chat_history\": chat_history\n",
        "      })\n",
        "      if isinstance(output, AgentFinish):\n",
        "          result = output.return_values[\"output\"]\n",
        "          if block_memory == False:\n",
        "            chat_history.append(HumanMessage(content=(prompt_text)))\n",
        "            chat_history.append(AIMessage(content=(output.return_values[\"output\"])))\n",
        "          break\n",
        "      else:\n",
        "          print(output.tool, output.tool_input)\n",
        "          if output.tool==\"show_history\":\n",
        "            block_memory = False\n",
        "            print(\"*** memory blocked\")\n",
        "          else:\n",
        "            block_memory = False\n",
        "          tool = tools_dict[output.tool]\n",
        "          observation = tool.run(output.tool_input)\n",
        "          intermediate_steps.append((output, observation))\n",
        "  block_memory == False\n",
        "  return result\n",
        "\n",
        "chat_response = chat_manual_loop(\"Kalkuliere die Versicherungsprämie für eine Versicherungssumme von 10000000\")\n",
        "print(chat_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXmSApHfCAZw",
        "outputId": "a69b5793-5df8-4179-ff55-6476d864a6dd"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "calculate_insurance_premium {'insured_sum': 10000000, 'currency': 'EUR', 'industry': 'construction'}\n",
            "show_hints {}\n",
            "Die Versicherungsprämie für eine Versicherungssumme von 10000000 EUR in der Baubranche beträgt 2500000.0 EUR (für Deutschland).\n",
            "\n",
            "Tipp zur Nutzung dieses Agents: Sie können nach allen Kundennamen und Prämien fragen, verwenden Sie dazu das CSV-Format und ';' als Trennzeichen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_response = chat_manual_loop(\"EUR, Die Branche ist Metallbau.\")\n",
        "print(chat_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyPfeoPPCjoU",
        "outputId": "a3bee83b-499c-43bf-cb81-75e19054bdbb"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Die Versicherungsprämie für eine Versicherungssumme von 10000000 EUR in der Metallbau-Branche beträgt 2500000.0 EUR (für Deutschland).\n",
            "\n",
            "Tipp zur Nutzung dieses Agents: Sie können nach allen Kundennamen und Prämien fragen, verwenden Sie dazu das CSV-Format und ';' als Trennzeichen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#chat_response = chat_manual_loop(\"Fasse alle letzten Nachrichten in einem Satz zusammen.\")\n",
        "chat_response = chat_manual_loop(\"Liste die letzten Berechnungen auf.\")\n",
        "#chat_response = chat_manual_loop(\"Using Custom Tool show me the history of my messages\")\n",
        "print(chat_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8MLl2hZCtuP",
        "outputId": "4e1535aa-e190-4507-c071-05635401d2d5"
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hier sind die letzten Berechnungen:\n",
            "\n",
            "1. Versicherungsprämie für eine Versicherungssumme von 10000000 EUR in der Baubranche: 2500000.0 EUR (für Deutschland)\n",
            "2. Versicherungsprämie für eine Versicherungssumme von 10000000 EUR in der Metallbau-Branche: 2500000.0 EUR (für Deutschland)\n",
            "\n",
            "Tipp zur Nutzung dieses Agents: Sie können nach allen Kundennamen und Prämien fragen, verwenden Sie dazu das CSV-Format und ';' als Trennzeichen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history_string = str(chat_history).replace(\"), \", \")§§§ \")[1:-1]\n",
        "print(chat_history_string)\n",
        "chat_history_array = chat_history_string.split(\"§§§ \")\n",
        "msg_history_string = \"\"\n",
        "for chat_string in chat_history_array:\n",
        "  tmp = chat_string.split(\"(content='\")\n",
        "  msg_history_string = msg_history_string + tmp[0] + \" - \" + tmp[1][:-2] + \"\\n\"\n",
        "print(msg_history_string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "fm_XIMGjJKpe",
        "outputId": "faf95fa8-2db1-4148-859c-5a5d82d60dc8"
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HumanMessage(content='Kalkuliere die Versicherungsprämie für eine Versicherungssumme von 10000000')§§§ AIMessage(content=\"Die Versicherungsprämie für eine Versicherungssumme von 10000000 EUR in der Baubranche beträgt 2500000.0 EUR (für Deutschland).\\n\\nTipp zur Nutzung dieses Agents: Sie können nach allen Kundennamen und Prämien fragen, verwenden Sie dazu das CSV-Format und ';' als Trennzeichen.\")§§§ HumanMessage(content='EUR, Die Branche ist Metallbau.')§§§ AIMessage(content=\"Die Versicherungsprämie für eine Versicherungssumme von 10000000 EUR in der Metallbau-Branche beträgt 2500000.0 EUR (für Deutschland).\\n\\nTipp zur Nutzung dieses Agents: Sie können nach allen Kundennamen und Prämien fragen, verwenden Sie dazu das CSV-Format und ';' als Trennzeichen.\")§§§ HumanMessage(content='Liste die letzten Berechnungen auf.')§§§ AIMessage(content=\"Hier sind die letzten Berechnungen:\\n\\n1. Versicherungsprämie für eine Versicherungssumme von 10000000 EUR in der Baubranche: 2500000.0 EUR (für Deutschland)\\n2. Versicherungsprämie für eine Versicherungssumme von 10000000 EUR in der Metallbau-Branche: 2500000.0 EUR (für Deutschland)\\n\\nTipp zur Nutzung dieses Agents: Sie können nach allen Kundennamen und Prämien fragen, verwenden Sie dazu das CSV-Format und ';' als Trennzeichen.\")§§§ HumanMessage(content='Berechne für Müller GmbH, Versicherungssumme von 5 MEUR, Branche Software')§§§ AIMessage(content=\"Die Versicherungsprämie für die Müller GmbH mit einer Versicherungssumme von 5 MEUR in der Software-Branche beträgt 2500000.0 EUR (für Deutschland).\\n\\nTipp zur Nutzung dieses Agents: Fragen Sie 'Zeigen Sie mir alle Kundennamen und Prämien, verwenden Sie das CSV-Format und ; als Trennzeichen'.\")§§§ HumanMessage(content='Berechne erneut, ändere die Versicherungssumme auf 2000000 EUR')§§§ AIMessage(content=\"Die Versicherungsprämie für eine Versicherungssumme von 2000000 EUR in der Baubranche beträgt 2500000.0 EUR (für Deutschland).\\n\\nTipp zur Nutzung dieses Agents: Fragen Sie 'Zeigen Sie mir alle Kundennamen und Prämien, verwenden Sie das CSV-Format und ; als Trennzeichen'.\")§§§ HumanMessage(content='Liste die letzten namentlich bekannten Kunden auf, bitte keine Dopplungen. Gib zusätzlich die angebotene Prämie an. Gib das Ergebnis im CSV-Format zurück, Trennzeichen ;')§§§ AIMessage(content=\"Hier sind die letzten namentlich bekannten Kunden und die angebotene Prämie:\\n\\n1. Müller GmbH; 2500000.0 EUR\\n\\nTipp zur Nutzung dieses Agents: Fragen Sie 'Zeigen Sie mir alle Kundennamen und Prämien, verwenden Sie das CSV-Format und ; als Trennzeichen'.\")\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-204-23d2d332b7c5>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchat_string\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchat_history_array\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchat_string\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"(content='\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mmsg_history_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmsg_history_string\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" - \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_history_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_response = chat_manual_loop(\"Berechne für Müller GmbH, Versicherungssumme von 5 MEUR, Branche Software\")\n",
        "print(chat_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KbFOg0YG4Sd",
        "outputId": "4a064fa1-0fe7-4d71-e45c-91b29574f310"
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Die Versicherungsprämie für die Müller GmbH mit einer Versicherungssumme von 5 MEUR in der Software-Branche beträgt 2500000.0 EUR (für Deutschland).\n",
            "\n",
            "Tipp zur Nutzung dieses Agents: Fragen Sie 'Zeigen Sie mir alle Kundennamen und Prämien, verwenden Sie das CSV-Format und ; als Trennzeichen'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_response = chat_manual_loop(\"Berechne erneut, ändere die Versicherungssumme auf 2000000 EUR\")\n",
        "print(chat_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sQfcROHQgeu",
        "outputId": "d0bfd0bf-1025-4c82-cbe9-d4d828491340"
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Die Versicherungsprämie für eine Versicherungssumme von 2000000 EUR in der Baubranche beträgt 2500000.0 EUR (für Deutschland).\n",
            "\n",
            "Tipp zur Nutzung dieses Agents: Fragen Sie 'Zeigen Sie mir alle Kundennamen und Prämien, verwenden Sie das CSV-Format und ; als Trennzeichen'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_response = chat_manual_loop(\"Liste die letzten namentlich bekannten Kunden auf, bitte keine Dopplungen. Gib zusätzlich die angebotene Prämie an. Gib das Ergebnis im CSV-Format zurück, Trennzeichen ;\")\n",
        "print(chat_response)"
      ],
      "metadata": {
        "id": "WZw1sP6UWGPm",
        "outputId": "9dba80a0-1419-4760-8365-e4aa61d0cbaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hier sind die letzten namentlich bekannten Kunden und die angebotene Prämie:\n",
            "\n",
            "1. Müller GmbH; 2500000.0 EUR\n",
            "\n",
            "Tipp zur Nutzung dieses Agents: Fragen Sie 'Zeigen Sie mir alle Kundennamen und Prämien, verwenden Sie das CSV-Format und ; als Trennzeichen'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show_history()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "Yvmgw3wYgAvo",
        "outputId": "2df05cae-9974-43bf-b674-50834440d98a"
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-203-a61e0de5b4b2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshow_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-164-385ddea14d87>\u001b[0m in \u001b[0;36mshow_history\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mchat_string\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchat_history_array\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m       \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchat_string\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"(content='\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m       \u001b[0mmsg_history_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmsg_history_string\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" - \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmsg_history_string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Memory from response object:\")\n",
        "chat_history_string = str(response[\"chat_history\"]).replace(\"), \", \")§§§ \")[1:-1]\n",
        "chat_history = chat_history_string.split(\"§§§ \")\n",
        "msg_history = []\n",
        "for chat_string in chat_history:\n",
        "  tmp = chat_string.split(\"(content='\")\n",
        "  msg_history.append({\"role\": tmp[0], \"content\": tmp[1][:-2]})\n",
        "#for msg in msg_history:\n",
        "#  print(msg)\n",
        "print('\\n'.join(str(x) for x in msg_history))"
      ],
      "metadata": {
        "id": "ZmCuWwuijWDD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27a971bd-8ef8-4047-c4ed-a69d911f7dc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory from response object:\n",
            "{'role': 'HumanMessage', 'content': 'Give me the premium for an insured sum of 10000000'}\n",
            "{'role': 'AIMessage', 'content': 'Sure, I can help with that. However, I also need to know the industry of the customer to calculate the insurance premium. Could you please provide that information?'}\n",
            "{'role': 'HumanMessage', 'content': 'The industry is chemical production'}\n",
            "{'role': 'AIMessage', 'content': 'The premium for an insured sum of 10,000,000 in the chemical production industry in Germany is 2,500,000.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradio Chat App for Agent"
      ],
      "metadata": {
        "id": "O_jGi0yQ-sEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Init agent and memory\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, memory=memory)\n",
        "messages = [{\"role\": \"assistant\", \"content\": \"How can I help you?\"}]\n",
        "\n",
        "#\n",
        "# Gradio app\n",
        "#\n",
        "\n",
        "# Theming\n",
        "theme = gr.themes.Default(\n",
        "    primary_hue=\"slate\" # , radius_size=gr.themes.Size(radius_sm=\"3px\", radius_xs=\"2px\", radius_xxs=\"1px\")\n",
        ")\n",
        "# Styling: Change max width\n",
        "css = \"\"\"\n",
        "  .gradio-container {max-width: 800px!important}\n",
        "  .vspacer1 {margin-top: 20px}\n",
        "\"\"\"\n",
        "\n",
        "with gr.Blocks(theme=theme, css=css) as demo:\n",
        "\n",
        "    gr.Markdown(\"# Agent Chat\", elem_classes=\"vspacer1\")\n",
        "\n",
        "    with gr.Tab(\"Chat\"):\n",
        "      # https://www.gradio.app/docs/chatbot\n",
        "\n",
        "      chatbot = gr.Chatbot(bubble_full_width=False)\n",
        "      msg = gr.Textbox()\n",
        "      clear = gr.ClearButton([msg, chatbot])\n",
        "\n",
        "      def ask(message, chat_history):\n",
        "          chat_history.append((message, None))\n",
        "          messages.append({\"role\": \"user\", \"content\": message})\n",
        "          return \"\", chat_history\n",
        "\n",
        "      def respond(chat_history):\n",
        "          prompt = chat_history[-1][0] # get prompt from history (last entry)\n",
        "          response = agent_executor.invoke({\"input\": prompt})\n",
        "          msg = {\"role\": \"assistant\", \"content\": response[\"output\"]}\n",
        "          messages.append(msg)\n",
        "          chat_history.append((None, response[\"output\"]))\n",
        "          print(\"\\n\\nMemory from response object:\")\n",
        "          print(textwrap.fill(str(response[\"chat_history\"]), 80))\n",
        "          return chat_history\n",
        "\n",
        "      msg.submit(ask, [msg, chatbot], [msg, chatbot], queue=False).then(\n",
        "        respond, chatbot, chatbot\n",
        "      )\n",
        "\n",
        "demo.launch(quiet=True, share=False, debug=True)"
      ],
      "metadata": {
        "id": "kioXkMb2-vUX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNQauzIuXKamwnBRqs26qm0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aknip/Langchain-etc./blob/main/Langchain-Agent-Insurance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Langchain Agent Insurance - using OpenAI functions\n",
        "\n",
        "Different agents and code implementations how to run Langchain agents using OpenAI functions: Single prompt, chat with memory, from command line or in Gradio web app, using AgentExecutor or your own custom loop.\n",
        "\n",
        "## How to use\n",
        "1. Run all cells of group \"Basic setup for all agents, tools and apps\"\n",
        "2. Run one of the two agent/tool groups\n",
        "3. Run different code implementations after that: CLI, Gradio, custom loops...\n",
        "\n",
        "For more information see https://levelup.gitconnected.com/building-a-powerful-agent-has-no-challenge-today-774e27be818d"
      ],
      "metadata": {
        "id": "_yJpe7D-EXzF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic setup for all agents, tools and apps"
      ],
      "metadata": {
        "id": "gOMfnUf3_oTj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "from getpass import getpass\n",
        "import psutil\n",
        "IN_NOTEBOOK = any([\"jupyter-notebook\" in i for i in psutil.Process().parent().cmdline()])\n",
        "if IN_NOTEBOOK:\n",
        "  CREDS = json.loads(getpass(\"Secrets (JSON string): \"))\n",
        "  os.environ['CREDS'] = json.dumps(CREDS)\n",
        "  CREDS = json.loads(os.getenv('CREDS'))"
      ],
      "metadata": {
        "id": "IWrCvpKaENeu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afIkZ1hD4RYB"
      },
      "outputs": [],
      "source": [
        "!pip install langchain==0.0.311 langchain-experimental==0.0.27 langchainhub==0.1.13 google-search-results==2.4.2 wikipedia==1.4.0 openai==0.28.1 gradio==3.47.1 -q\n",
        "%load_ext gradio\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import Tool, AgentExecutor\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain import hub\n",
        "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain.utilities import SerpAPIWrapper, SQLDatabase, WikipediaAPIWrapper\n",
        "from langchain_experimental.sql import SQLDatabaseChain\n",
        "from langchain.tools import WikipediaQueryRun\n",
        "from langchain.agents.format_scratchpad import format_to_openai_functions\n",
        "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
        "from langchain.tools.render import format_tool_to_openai_function\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain.tools import BaseTool, StructuredTool\n",
        "from langchain.schema.agent import AgentFinish\n",
        "from langchain.schema import BaseMessage, AIMessage, HumanMessage\n",
        "import os\n",
        "import langchain\n",
        "import openai\n",
        "import textwrap\n",
        "import gradio as gr\n",
        "import random\n",
        "import time"
      ],
      "metadata": {
        "id": "CEhw8Ye15BgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agent 2: Calculate insurance premium"
      ],
      "metadata": {
        "id": "EoYqbRg0_w19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = CREDS['OpenAI']['v2']['credential']\n",
        "llm = ChatOpenAI(temperature=0, model='gpt-4-0613')\n",
        "\n",
        "def calculate_insurance_premium(insured_sum: int, industry: str, country: str = \"Germany\") -> float:\n",
        "    \"\"\"Calculate the premium for an insurance based on the maximum insured sum and the industry of the customer.\"\"\"\n",
        "    premium = insured_sum*0.25\n",
        "    result = str(premium) + \" (for \" + country + \")\"\n",
        "    return result\n",
        "\n",
        "calc_tool = StructuredTool.from_function(calculate_insurance_premium, return_direct=False)\n",
        "\n",
        "def show_history() -> str:\n",
        "    \"\"\"Show the history of the chat or conversation to the user.\"\"\"\n",
        "    chat_history_string = str(chat_history).replace(\"), \", \")§§§ \")[1:-1]\n",
        "    chat_history_array = chat_history_string.split(\"§§§ \")\n",
        "    msg_history_string = \"\"\n",
        "    for chat_string in chat_history_array:\n",
        "      tmp = chat_string.split(\"(content='\")\n",
        "      msg_history_string = msg_history_string + tmp[0] + \" - \" + tmp[1][:-2] + \"\\n\"\n",
        "    return msg_history_string\n",
        "\n",
        "show_history_tool = StructuredTool.from_function(show_history, return_direct=True)\n",
        "\n",
        "tools = [calc_tool, show_history_tool]\n",
        "tools_as_openai_functions = [format_tool_to_openai_function(t) for t in tools]\n",
        "tools_dict = {\n",
        "    \"calculate_insurance_premium\": calc_tool,\n",
        "    \"show_history\": show_history_tool\n",
        "    }\n",
        "\n",
        "llm_with_tools = llm.bind(\n",
        "    functions=tools_as_openai_functions\n",
        ")\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a useful assistant.\"),\n",
        "    MessagesPlaceholder(variable_name='chat_history'),\n",
        "    (\"user\", \"{input}\"),\n",
        "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "])\n",
        "\n",
        "agent = {\n",
        "    \"input\": lambda x: x[\"input\"],\n",
        "    \"agent_scratchpad\": lambda x: format_to_openai_functions(x['intermediate_steps']),\n",
        "    \"chat_history\": lambda x: x[\"chat_history\"]\n",
        "} | prompt | llm_with_tools | OpenAIFunctionsAgentOutputParser()\n"
      ],
      "metadata": {
        "id": "vAzSbqz7_0_U"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# show calc_tool as OpenAI function\n",
        "print(json.dumps(format_tool_to_openai_function(calc_tool), sort_keys=False, indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Gn4scosGVNK",
        "outputId": "bcea8102-849b-4501-a98b-483d126c14e1",
        "cellView": "form",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"name\": \"calculate_insurance_premium\",\n",
            "  \"description\": \"calculate_insurance_premium(insured_sum: int, industry: str, country: str = 'Germany') -> float - Calculate the premium for an insurance based on the maximum insured sum and the industry of the customer.\",\n",
            "  \"parameters\": {\n",
            "    \"title\": \"calculate_insurance_premiumSchemaSchema\",\n",
            "    \"type\": \"object\",\n",
            "    \"properties\": {\n",
            "      \"insured_sum\": {\n",
            "        \"title\": \"Insured Sum\",\n",
            "        \"type\": \"integer\"\n",
            "      },\n",
            "      \"industry\": {\n",
            "        \"title\": \"Industry\",\n",
            "        \"type\": \"string\"\n",
            "      },\n",
            "      \"country\": {\n",
            "        \"title\": \"Country\",\n",
            "        \"default\": \"Germany\",\n",
            "        \"type\": \"string\"\n",
            "      }\n",
            "    },\n",
            "    \"required\": [\n",
            "      \"insured_sum\",\n",
            "      \"industry\"\n",
            "    ]\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "demoSchema = {\n",
        "  \"name\": \"calculate_insurance_premium\",\n",
        "  \"description\": \"calculate_insurance_premium(insured_sum: int, industry: str, country: str = 'Germany') -> float - Calculate the premium for an insurance based on the maximum insured sum and the industry of the customer.\",\n",
        "  \"parameters\": {\n",
        "    \"title\": \"calculate_insurance_premiumSchemaSchema\",\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\n",
        "      \"insured_sum\": {\n",
        "        \"title\": \"Insured Sum\",\n",
        "        \"type\": \"integer\"\n",
        "      },\n",
        "      \"industry\": {\n",
        "        \"title\": \"Industry\",\n",
        "        \"type\": \"string\"\n",
        "      },\n",
        "      \"country\": {\n",
        "        \"title\": \"Country\",\n",
        "        \"default\": \"Germany\",\n",
        "        \"type\": \"string\",\n",
        "        \"enum\": [\"positive\", \"negative\"],\n",
        "        \"description\": \"The Country where the insured company is located\"\n",
        "      }\n",
        "    },\n",
        "    \"required\": [\n",
        "      \"insured_sum\",\n",
        "      \"industry\"\n",
        "    ]\n",
        "  }\n",
        "}"
      ],
      "metadata": {
        "id": "AFRanByCQJAW",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chat loop"
      ],
      "metadata": {
        "id": "-fL3b1FXIx9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "langchain.debug = False\n",
        "\n",
        "intermediate_steps = []\n",
        "chat_history = []\n",
        "\n",
        "# manual loop / like AgentExecutor\n",
        "def chat_manual_loop(prompt_text: str) -> str:\n",
        "  block_memory = False\n",
        "  while True:\n",
        "      output = agent.invoke({\n",
        "          \"input\": prompt_text,\n",
        "          \"intermediate_steps\": intermediate_steps,\n",
        "          \"chat_history\": chat_history\n",
        "      })\n",
        "      if isinstance(output, AgentFinish):\n",
        "          result = output.return_values[\"output\"]\n",
        "          if block_memory == False:\n",
        "            chat_history.append(HumanMessage(content=(prompt_text)))\n",
        "            chat_history.append(AIMessage(content=(output.return_values[\"output\"])))\n",
        "          break\n",
        "      else:\n",
        "          print(output.tool, output.tool_input)\n",
        "          if output.tool==\"show_history\":\n",
        "            block_memory = True\n",
        "            print(\"*** memory blocked\")\n",
        "          else:\n",
        "            block_memory = False\n",
        "          tool = tools_dict[output.tool]\n",
        "          observation = tool.run(output.tool_input)\n",
        "          intermediate_steps.append((output, observation))\n",
        "  block_memory == False\n",
        "  return result\n",
        "\n",
        "chat_response = chat_manual_loop(\"Kalkuliere die Versicherungsprämie für eine Versicherungssumme von 10000000\")\n",
        "print(chat_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXmSApHfCAZw",
        "outputId": "d646ae40-e42e-43d2-92d7-baafa27db80d"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Natürlich, ich kann das für Sie berechnen. Könnten Sie mir bitte noch mitteilen, in welcher Branche Sie tätig sind und in welchem Land Sie sich befinden? Diese Informationen sind für die Berechnung der Versicherungsprämie relevant.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_response = chat_manual_loop(\"Die Branche ist Metallbau.\")\n",
        "print(chat_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyPfeoPPCjoU",
        "outputId": "ca4c424f-e054-49ef-e738-504e525c6792"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "calculate_insurance_premium {'insured_sum': 10000000, 'industry': 'Metallbau'}\n",
            "Die Versicherungsprämie für eine Versicherungssumme von 10.000.000 in der Branche Metallbau in Deutschland beträgt 2.500.000 Euro.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_response = chat_manual_loop(\"show me the history of my messages\")\n",
        "print(chat_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8MLl2hZCtuP",
        "outputId": "ea1e4f2e-ceb3-43fe-dea5-926233ad4187"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Die Versicherungsprämie für eine Versicherungssumme von 1.000.000 in der Branche Software in Deutschland beträgt 250.000 Euro.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history_string = str(chat_history).replace(\"), \", \")§§§ \")[1:-1]\n",
        "print(chat_history_string)\n",
        "chat_history_array = chat_history_string.split(\"§§§ \")\n",
        "msg_history_string = \"\"\n",
        "for chat_string in chat_history_array:\n",
        "  tmp = chat_string.split(\"(content='\")\n",
        "  msg_history_string = msg_history_string + tmp[0] + \" - \" + tmp[1][:-2] + \"\\n\"\n",
        "print(msg_history_string)"
      ],
      "metadata": {
        "id": "fm_XIMGjJKpe",
        "outputId": "1d527b3b-4cec-40d2-d24f-c509d596f2f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HumanMessage(content='Kalkuliere die Versicherungsprämie für eine Versicherungssumme von 10000000')§§§ AIMessage(content='Natürlich, ich kann das für Sie berechnen. Könnten Sie mir bitte noch mitteilen, in welcher Branche Sie tätig sind und in welchem Land Sie sich befinden? Diese Informationen sind für die Berechnung der Versicherungsprämie relevant.')§§§ HumanMessage(content='Die Branche ist Metallbau.')§§§ AIMessage(content='Die Versicherungsprämie für eine Versicherungssumme von 10.000.000 in der Branche Metallbau in Deutschland beträgt 2.500.000 Euro.')§§§ HumanMessage(content='Berechne für eine Versicherungssumme von 20000000, Branche Chemie')§§§ AIMessage(content='Die Versicherungsprämie für eine Versicherungssumme von 20.000.000 in der Branche Chemie in Deutschland beträgt 5.000.000 Euro.')§§§ HumanMessage(content='Berechne für eine Versicherungssumme von 1000000, Branche Software')§§§ AIMessage(content='Die Versicherungsprämie für eine Versicherungssumme von 1.000.000 in der Branche Software in Deutschland beträgt 250.000 Euro.')\n",
            "HumanMessage - Kalkuliere die Versicherungsprämie für eine Versicherungssumme von 10000000\n",
            "AIMessage - Natürlich, ich kann das für Sie berechnen. Könnten Sie mir bitte noch mitteilen, in welcher Branche Sie tätig sind und in welchem Land Sie sich befinden? Diese Informationen sind für die Berechnung der Versicherungsprämie relevant.\n",
            "HumanMessage - Die Branche ist Metallbau.\n",
            "AIMessage - Die Versicherungsprämie für eine Versicherungssumme von 10.000.000 in der Branche Metallbau in Deutschland beträgt 2.500.000 Euro.\n",
            "HumanMessage - Berechne für eine Versicherungssumme von 20000000, Branche Chemie\n",
            "AIMessage - Die Versicherungsprämie für eine Versicherungssumme von 20.000.000 in der Branche Chemie in Deutschland beträgt 5.000.000 Euro.\n",
            "HumanMessage - Berechne für eine Versicherungssumme von 1000000, Branche Software\n",
            "AIMessage - Die Versicherungsprämie für eine Versicherungssumme von 1.000.000 in der Branche Software in Deutschland beträgt 250.000 Euro.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_response = chat_manual_loop(\"Berechne für eine Versicherungssumme von 1000000, Branche Software\")\n",
        "print(chat_response)"
      ],
      "metadata": {
        "id": "_KbFOg0YG4Sd",
        "outputId": "274ad172-7942-4c22-d4a0-9c784dbea2dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "calculate_insurance_premium {'insured_sum': 1000000, 'industry': 'Software'}\n",
            "Die Versicherungsprämie für eine Versicherungssumme von 1.000.000 in der Branche Software in Deutschland beträgt 250.000 Euro.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show_history()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "id": "Yvmgw3wYgAvo",
        "outputId": "758c1b60-b78f-4f9f-db8f-0ce7d91239bc"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'HumanMessage - Kalkuliere die Versicherungsprämie für eine Versicherungssumme von 10000000\\nAIMessage - Natürlich, ich kann das für Sie berechnen. Könnten Sie mir bitte noch mitteilen, in welcher Branche Sie tätig sind und in welchem Land Sie sich befinden? Diese Informationen sind für die Berechnung der Versicherungsprämie relevant.\\nHumanMessage - Die Branche ist Metallbau.\\nAIMessage - Die Versicherungsprämie für eine Versicherungssumme von 10.000.000 in der Branche Metallbau in Deutschland beträgt 2.500.000 Euro.\\nHumanMessage - Berechne für eine Versicherungssumme von 20000000, Branche Chemie\\nAIMessage - Die Versicherungsprämie für eine Versicherungssumme von 20.000.000 in der Branche Chemie in Deutschland beträgt 5.000.000 Euro.\\nHumanMessage - Berechne für eine Versicherungssumme von 1000000, Branche Software\\nAIMessage - Die Versicherungsprämie für eine Versicherungssumme von 1.000.000 in der Branche Software in Deutschland beträgt 250.000 Euro.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Memory from response object:\")\n",
        "chat_history_string = str(response[\"chat_history\"]).replace(\"), \", \")§§§ \")[1:-1]\n",
        "chat_history = chat_history_string.split(\"§§§ \")\n",
        "msg_history = []\n",
        "for chat_string in chat_history:\n",
        "  tmp = chat_string.split(\"(content='\")\n",
        "  msg_history.append({\"role\": tmp[0], \"content\": tmp[1][:-2]})\n",
        "#for msg in msg_history:\n",
        "#  print(msg)\n",
        "print('\\n'.join(str(x) for x in msg_history))"
      ],
      "metadata": {
        "id": "ZmCuWwuijWDD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27a971bd-8ef8-4047-c4ed-a69d911f7dc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory from response object:\n",
            "{'role': 'HumanMessage', 'content': 'Give me the premium for an insured sum of 10000000'}\n",
            "{'role': 'AIMessage', 'content': 'Sure, I can help with that. However, I also need to know the industry of the customer to calculate the insurance premium. Could you please provide that information?'}\n",
            "{'role': 'HumanMessage', 'content': 'The industry is chemical production'}\n",
            "{'role': 'AIMessage', 'content': 'The premium for an insured sum of 10,000,000 in the chemical production industry in Germany is 2,500,000.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradio Chat App for Agent"
      ],
      "metadata": {
        "id": "O_jGi0yQ-sEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Init agent and memory\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, memory=memory)\n",
        "messages = [{\"role\": \"assistant\", \"content\": \"How can I help you?\"}]\n",
        "\n",
        "#\n",
        "# Gradio app\n",
        "#\n",
        "\n",
        "# Theming\n",
        "theme = gr.themes.Default(\n",
        "    primary_hue=\"slate\" # , radius_size=gr.themes.Size(radius_sm=\"3px\", radius_xs=\"2px\", radius_xxs=\"1px\")\n",
        ")\n",
        "# Styling: Change max width\n",
        "css = \"\"\"\n",
        "  .gradio-container {max-width: 800px!important}\n",
        "  .vspacer1 {margin-top: 20px}\n",
        "\"\"\"\n",
        "\n",
        "with gr.Blocks(theme=theme, css=css) as demo:\n",
        "\n",
        "    gr.Markdown(\"# Agent Chat\", elem_classes=\"vspacer1\")\n",
        "\n",
        "    with gr.Tab(\"Chat\"):\n",
        "      # https://www.gradio.app/docs/chatbot\n",
        "\n",
        "      chatbot = gr.Chatbot(bubble_full_width=False)\n",
        "      msg = gr.Textbox()\n",
        "      clear = gr.ClearButton([msg, chatbot])\n",
        "\n",
        "      def ask(message, chat_history):\n",
        "          chat_history.append((message, None))\n",
        "          messages.append({\"role\": \"user\", \"content\": message})\n",
        "          return \"\", chat_history\n",
        "\n",
        "      def respond(chat_history):\n",
        "          prompt = chat_history[-1][0] # get prompt from history (last entry)\n",
        "          response = agent_executor.invoke({\"input\": prompt})\n",
        "          msg = {\"role\": \"assistant\", \"content\": response[\"output\"]}\n",
        "          messages.append(msg)\n",
        "          chat_history.append((None, response[\"output\"]))\n",
        "          print(\"\\n\\nMemory from response object:\")\n",
        "          print(textwrap.fill(str(response[\"chat_history\"]), 80))\n",
        "          return chat_history\n",
        "\n",
        "      msg.submit(ask, [msg, chatbot], [msg, chatbot], queue=False).then(\n",
        "        respond, chatbot, chatbot\n",
        "      )\n",
        "\n",
        "demo.launch(quiet=True, share=False, debug=True)"
      ],
      "metadata": {
        "id": "kioXkMb2-vUX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
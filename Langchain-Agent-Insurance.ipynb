{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPDLkqNURy+PF8piPfWr/mk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aknip/Langchain-etc./blob/main/Langchain-Agent-Insurance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Langchain Agent Insurance - using OpenAI functions\n",
        "\n",
        "Different agents and code implementations how to run Langchain agents using OpenAI functions: Single prompt, chat with memory, from command line or in Gradio web app, using AgentExecutor or your own custom loop.\n",
        "\n",
        "## How to use\n",
        "1. Run all cells of group \"Basic setup for all agents, tools and apps\"\n",
        "2. Run one of the two agent/tool groups\n",
        "3. Run different code implementations after that: CLI, Gradio, custom loops...\n",
        "\n",
        "For more information see https://levelup.gitconnected.com/building-a-powerful-agent-has-no-challenge-today-774e27be818d"
      ],
      "metadata": {
        "id": "_yJpe7D-EXzF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic setup for all agents, tools and apps"
      ],
      "metadata": {
        "id": "gOMfnUf3_oTj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "from getpass import getpass\n",
        "import psutil\n",
        "IN_NOTEBOOK = any([\"jupyter-notebook\" in i for i in psutil.Process().parent().cmdline()])\n",
        "if IN_NOTEBOOK:\n",
        "  CREDS = json.loads(getpass(\"Secrets (JSON string): \"))\n",
        "  os.environ['CREDS'] = json.dumps(CREDS)\n",
        "  CREDS = json.loads(os.getenv('CREDS'))"
      ],
      "metadata": {
        "id": "IWrCvpKaENeu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afIkZ1hD4RYB"
      },
      "outputs": [],
      "source": [
        "!pip install langchain==0.0.311 langchain-experimental==0.0.27 langchainhub==0.1.13 google-search-results==2.4.2 wikipedia==1.4.0 openai==0.28.1 gradio==3.47.1 -q\n",
        "%load_ext gradio\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import Tool, AgentExecutor\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain import hub\n",
        "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain.utilities import SerpAPIWrapper, SQLDatabase, WikipediaAPIWrapper\n",
        "from langchain_experimental.sql import SQLDatabaseChain\n",
        "from langchain.tools import WikipediaQueryRun\n",
        "from langchain.agents.format_scratchpad import format_to_openai_functions\n",
        "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
        "from langchain.tools.render import format_tool_to_openai_function\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain.tools import BaseTool, StructuredTool\n",
        "from langchain.schema.agent import AgentFinish\n",
        "from langchain.schema import BaseMessage, AIMessage, HumanMessage\n",
        "import os\n",
        "import langchain\n",
        "import openai\n",
        "import textwrap\n",
        "import gradio as gr\n",
        "import random\n",
        "import time"
      ],
      "metadata": {
        "id": "CEhw8Ye15BgC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agent 2: Calculate insurance premium"
      ],
      "metadata": {
        "id": "EoYqbRg0_w19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = CREDS['OpenAI']['v2']['credential']\n",
        "llm = ChatOpenAI(temperature=0, model='gpt-4-0613')\n",
        "\n",
        "def calculate_insurance_premium(insured_sum: int, industry: str, country: str = \"Germany\") -> float:\n",
        "    \"\"\"Calculate the premium for an insurance based on the maximum insured sum and the industry of the customer.\"\"\"\n",
        "    premium = insured_sum*0.25\n",
        "    result = str(premium) + \" (for \" + country + \")\"\n",
        "    return result\n",
        "\n",
        "def show_history() -> str:\n",
        "    \"\"\"Show the history of the chat or conversation to the user.\"\"\"\n",
        "    chat_history_string = str(response[\"chat_history\"]).replace(\"), \", \")§§§ \")[1:-1]\n",
        "    chat_history = chat_history_string.split(\"§§§ \")\n",
        "    msg_history = []\n",
        "    for chat_string in chat_history:\n",
        "      tmp = chat_string.split(\"(content='\")\n",
        "      msg_history.append({\"role\": tmp[0], \"content\": tmp[1][:-2]})\n",
        "    #for msg in msg_history:\n",
        "    #  print(msg)\n",
        "    msg_history_string = '\\n'.join(str(x) for x in msg_history)\n",
        "    return msg_history_string\n",
        "\n",
        "\n",
        "calc_tool = StructuredTool.from_function(calculate_insurance_premium, return_direct=False)\n",
        "tools = [calc_tool]\n",
        "tools_as_openai_functions = [format_tool_to_openai_function(t) for t in tools]\n",
        "\n",
        "llm_with_tools = llm.bind(\n",
        "    functions=tools_as_openai_functions\n",
        ")\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a useful assistant.\"),\n",
        "    MessagesPlaceholder(variable_name='chat_history'),\n",
        "    (\"user\", \"{input}\"),\n",
        "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "])\n",
        "\n",
        "agent = {\n",
        "    \"input\": lambda x: x[\"input\"],\n",
        "    \"agent_scratchpad\": lambda x: format_to_openai_functions(x['intermediate_steps']),\n",
        "    \"chat_history\": lambda x: x[\"chat_history\"]\n",
        "} | prompt | llm_with_tools | OpenAIFunctionsAgentOutputParser()\n"
      ],
      "metadata": {
        "id": "vAzSbqz7_0_U"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# show calc_tool as OpenAI function\n",
        "print(json.dumps(format_tool_to_openai_function(calc_tool), sort_keys=False, indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Gn4scosGVNK",
        "outputId": "bcea8102-849b-4501-a98b-483d126c14e1",
        "cellView": "form",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"name\": \"calculate_insurance_premium\",\n",
            "  \"description\": \"calculate_insurance_premium(insured_sum: int, industry: str, country: str = 'Germany') -> float - Calculate the premium for an insurance based on the maximum insured sum and the industry of the customer.\",\n",
            "  \"parameters\": {\n",
            "    \"title\": \"calculate_insurance_premiumSchemaSchema\",\n",
            "    \"type\": \"object\",\n",
            "    \"properties\": {\n",
            "      \"insured_sum\": {\n",
            "        \"title\": \"Insured Sum\",\n",
            "        \"type\": \"integer\"\n",
            "      },\n",
            "      \"industry\": {\n",
            "        \"title\": \"Industry\",\n",
            "        \"type\": \"string\"\n",
            "      },\n",
            "      \"country\": {\n",
            "        \"title\": \"Country\",\n",
            "        \"default\": \"Germany\",\n",
            "        \"type\": \"string\"\n",
            "      }\n",
            "    },\n",
            "    \"required\": [\n",
            "      \"insured_sum\",\n",
            "      \"industry\"\n",
            "    ]\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "demoSchema = {\n",
        "  \"name\": \"calculate_insurance_premium\",\n",
        "  \"description\": \"calculate_insurance_premium(insured_sum: int, industry: str, country: str = 'Germany') -> float - Calculate the premium for an insurance based on the maximum insured sum and the industry of the customer.\",\n",
        "  \"parameters\": {\n",
        "    \"title\": \"calculate_insurance_premiumSchemaSchema\",\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\n",
        "      \"insured_sum\": {\n",
        "        \"title\": \"Insured Sum\",\n",
        "        \"type\": \"integer\"\n",
        "      },\n",
        "      \"industry\": {\n",
        "        \"title\": \"Industry\",\n",
        "        \"type\": \"string\"\n",
        "      },\n",
        "      \"country\": {\n",
        "        \"title\": \"Country\",\n",
        "        \"default\": \"Germany\",\n",
        "        \"type\": \"string\",\n",
        "        \"enum\": [\"positive\", \"negative\"],\n",
        "        \"description\": \"The Country where the insured company is located\"\n",
        "      }\n",
        "    },\n",
        "    \"required\": [\n",
        "      \"insured_sum\",\n",
        "      \"industry\"\n",
        "    ]\n",
        "  }\n",
        "}"
      ],
      "metadata": {
        "id": "AFRanByCQJAW",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CLI for agent_executor (Chatbot with memory)"
      ],
      "metadata": {
        "id": "-fL3b1FXIx9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, memory=memory)\n",
        "messages = [{\"role\": \"assistant\", \"content\": \"How can I help you?\"}]\n",
        "langchain.debug = False"
      ],
      "metadata": {
        "id": "qVfrjxhuUbn9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Give me the premium for an insured sum of 10000000\"\n",
        "#prompt = \"The industry is chemical production\"\n",
        "messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "print(\"user: \" + prompt)\n",
        "response = agent_executor.invoke({\"input\": prompt})\n",
        "msg = {\"role\": \"assistant\", \"content\": response[\"output\"]}\n",
        "messages.append(msg)\n",
        "print(textwrap.fill(\"assistant: \" + response[\"output\"], 80))\n",
        "print(\"\\nHistory:\")\n",
        "for msg in messages:\n",
        "    #st.chat_message(msg[\"role\"]).write(msg[\"content\"])\n",
        "    print(textwrap.fill(msg[\"role\"] + \": \" + msg[\"content\"], 80))"
      ],
      "metadata": {
        "id": "OjDvg8GSaSP8",
        "outputId": "3ea9939d-bfbf-4783-90c6-338fb463bd14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user: Give me the premium for an insured sum of 10000000\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mSure, I can help with that. However, I also need to know the industry of the customer to calculate the insurance premium. Could you please provide that information?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "assistant: Sure, I can help with that. However, I also need to know the industry\n",
            "of the customer to calculate the insurance premium. Could you please provide\n",
            "that information?\n",
            "\n",
            "History:\n",
            "assistant: How can I help you?\n",
            "user: Give me the premium for an insured sum of 10000000\n",
            "assistant: Sure, I can help with that. However, I also need to know the industry\n",
            "of the customer to calculate the insurance premium. Could you please provide\n",
            "that information?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show_history()"
      ],
      "metadata": {
        "id": "Yvmgw3wYgAvo",
        "outputId": "529bc663-052c-4404-b8b6-3a569d27a7c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"{'role': 'HumanMessage', 'content': 'Give me the premium for an insured sum of 10000000'}\\n{'role': 'AIMessage', 'content': 'Sure, I can help with that. However, I also need to know the industry of the customer to calculate the insurance premium. Could you please provide that information?'}\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Memory from response object:\")\n",
        "chat_history_string = str(response[\"chat_history\"]).replace(\"), \", \")§§§ \")[1:-1]\n",
        "chat_history = chat_history_string.split(\"§§§ \")\n",
        "msg_history = []\n",
        "for chat_string in chat_history:\n",
        "  tmp = chat_string.split(\"(content='\")\n",
        "  msg_history.append({\"role\": tmp[0], \"content\": tmp[1][:-2]})\n",
        "#for msg in msg_history:\n",
        "#  print(msg)\n",
        "print('\\n'.join(str(x) for x in msg_history))"
      ],
      "metadata": {
        "id": "ZmCuWwuijWDD",
        "outputId": "27a971bd-8ef8-4047-c4ed-a69d911f7dc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory from response object:\n",
            "{'role': 'HumanMessage', 'content': 'Give me the premium for an insured sum of 10000000'}\n",
            "{'role': 'AIMessage', 'content': 'Sure, I can help with that. However, I also need to know the industry of the customer to calculate the insurance premium. Could you please provide that information?'}\n",
            "{'role': 'HumanMessage', 'content': 'The industry is chemical production'}\n",
            "{'role': 'AIMessage', 'content': 'The premium for an insured sum of 10,000,000 in the chemical production industry in Germany is 2,500,000.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradio Chat App for Agent"
      ],
      "metadata": {
        "id": "O_jGi0yQ-sEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Init agent and memory\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, memory=memory)\n",
        "messages = [{\"role\": \"assistant\", \"content\": \"How can I help you?\"}]\n",
        "\n",
        "#\n",
        "# Gradio app\n",
        "#\n",
        "\n",
        "# Theming\n",
        "theme = gr.themes.Default(\n",
        "    primary_hue=\"slate\" # , radius_size=gr.themes.Size(radius_sm=\"3px\", radius_xs=\"2px\", radius_xxs=\"1px\")\n",
        ")\n",
        "# Styling: Change max width\n",
        "css = \"\"\"\n",
        "  .gradio-container {max-width: 800px!important}\n",
        "  .vspacer1 {margin-top: 20px}\n",
        "\"\"\"\n",
        "\n",
        "with gr.Blocks(theme=theme, css=css) as demo:\n",
        "\n",
        "    gr.Markdown(\"# Agent Chat\", elem_classes=\"vspacer1\")\n",
        "\n",
        "    with gr.Tab(\"Chat\"):\n",
        "      # https://www.gradio.app/docs/chatbot\n",
        "\n",
        "      chatbot = gr.Chatbot(bubble_full_width=False)\n",
        "      msg = gr.Textbox()\n",
        "      clear = gr.ClearButton([msg, chatbot])\n",
        "\n",
        "      def ask(message, chat_history):\n",
        "          chat_history.append((message, None))\n",
        "          messages.append({\"role\": \"user\", \"content\": message})\n",
        "          return \"\", chat_history\n",
        "\n",
        "      def respond(chat_history):\n",
        "          prompt = chat_history[-1][0] # get prompt from history (last entry)\n",
        "          response = agent_executor.invoke({\"input\": prompt})\n",
        "          msg = {\"role\": \"assistant\", \"content\": response[\"output\"]}\n",
        "          messages.append(msg)\n",
        "          chat_history.append((None, response[\"output\"]))\n",
        "          print(\"\\n\\nMemory from response object:\")\n",
        "          print(textwrap.fill(str(response[\"chat_history\"]), 80))\n",
        "          return chat_history\n",
        "\n",
        "      msg.submit(ask, [msg, chatbot], [msg, chatbot], queue=False).then(\n",
        "        respond, chatbot, chatbot\n",
        "      )\n",
        "\n",
        "demo.launch(quiet=True, share=False, debug=True)"
      ],
      "metadata": {
        "id": "kioXkMb2-vUX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
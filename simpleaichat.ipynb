{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aknip/Langchain-etc./blob/main/simpleaichat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q simpleaichat"
      ],
      "metadata": {
        "id": "Ch7s6QJUx4CX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"pydantic>=2.0\" \"fire>=0.3.0\" \"httpx>=0.24.1\" \"python-dotenv>=1.0.0\" \"orjson>=3.9.0\" \"rich>=13.4.1\" \"python-dateutil>=2.8.2\""
      ],
      "metadata": {
        "id": "g9YiDAFONffJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "import os\n",
        "import datetime\n",
        "import dateutil\n",
        "from uuid import uuid4, UUID\n",
        "from contextlib import contextmanager, asynccontextmanager\n",
        "import csv\n",
        "\n",
        "from pydantic import BaseModel\n",
        "from httpx import Client, AsyncClient\n",
        "from typing import List, Dict, Union, Optional, Any\n",
        "import orjson\n",
        "from dotenv import load_dotenv\n",
        "from rich.console import Console\n",
        "\n",
        "\n",
        "import os\n",
        "import httpx\n",
        "from typing import List, Union\n",
        "from pydantic import Field\n",
        "\n",
        "WIKIPEDIA_API_URL = \"https://en.wikipedia.org/w/api.php\"\n",
        "\n",
        "\n",
        "def wikipedia_search(query: str, n: int = 1) -> Union[str, List[str]]:\n",
        "    SEARCH_PARAMS = {\n",
        "        \"action\": \"query\",\n",
        "        \"list\": \"search\",\n",
        "        \"format\": \"json\",\n",
        "        \"srlimit\": n,\n",
        "        \"srsearch\": query,\n",
        "        \"srwhat\": \"text\",\n",
        "        \"srprop\": \"\",\n",
        "    }\n",
        "\n",
        "    r_search = httpx.get(WIKIPEDIA_API_URL, params=SEARCH_PARAMS)\n",
        "    results = [x[\"title\"] for x in r_search.json()[\"query\"][\"search\"]]\n",
        "\n",
        "    return results[0] if n == 1 else results\n",
        "\n",
        "\n",
        "def wikipedia_lookup(query: str, sentences: int = 1) -> str:\n",
        "    LOOKUP_PARAMS = {\n",
        "        \"action\": \"query\",\n",
        "        \"prop\": \"extracts\",\n",
        "        \"exsentences\": sentences,\n",
        "        \"exlimit\": \"1\",\n",
        "        \"explaintext\": \"1\",\n",
        "        \"formatversion\": \"2\",\n",
        "        \"format\": \"json\",\n",
        "        \"titles\": query,\n",
        "    }\n",
        "\n",
        "    r_lookup = httpx.get(WIKIPEDIA_API_URL, params=LOOKUP_PARAMS)\n",
        "    return r_lookup.json()[\"query\"][\"pages\"][0][\"extract\"]\n",
        "\n",
        "\n",
        "def wikipedia_search_lookup(query: str, sentences: int = 1) -> str:\n",
        "    return wikipedia_lookup(wikipedia_search(query, 1), sentences)\n",
        "\n",
        "\n",
        "async def wikipedia_search_async(query: str, n: int = 1) -> Union[str, List[str]]:\n",
        "    SEARCH_PARAMS = {\n",
        "        \"action\": \"query\",\n",
        "        \"list\": \"search\",\n",
        "        \"format\": \"json\",\n",
        "        \"srlimit\": n,\n",
        "        \"srsearch\": query,\n",
        "        \"srwhat\": \"text\",\n",
        "        \"srprop\": \"\",\n",
        "    }\n",
        "\n",
        "    async with httpx.AsyncClient(proxies=os.getenv(\"https_proxy\")) as client:\n",
        "        r_search = await client.get(WIKIPEDIA_API_URL, params=SEARCH_PARAMS)\n",
        "    results = [x[\"title\"] for x in r_search.json()[\"query\"][\"search\"]]\n",
        "\n",
        "    return results[0] if n == 1 else results\n",
        "\n",
        "\n",
        "async def wikipedia_lookup_async(query: str, sentences: int = 1) -> str:\n",
        "    LOOKUP_PARAMS = {\n",
        "        \"action\": \"query\",\n",
        "        \"prop\": \"extracts\",\n",
        "        \"exsentences\": sentences,\n",
        "        \"exlimit\": \"1\",\n",
        "        \"explaintext\": \"1\",\n",
        "        \"formatversion\": \"2\",\n",
        "        \"format\": \"json\",\n",
        "        \"titles\": query,\n",
        "    }\n",
        "\n",
        "    async with httpx.AsyncClient(proxies=os.getenv(\"https_proxy\")) as client:\n",
        "        r_lookup = await client.get(WIKIPEDIA_API_URL, params=LOOKUP_PARAMS)\n",
        "    return r_lookup.json()[\"query\"][\"pages\"][0][\"extract\"]\n",
        "\n",
        "\n",
        "async def wikipedia_search_lookup_async(query: str, sentences: int = 1) -> str:\n",
        "    return await wikipedia_lookup_async(\n",
        "        await wikipedia_search_async(query, 1), sentences\n",
        "    )\n",
        "\n",
        "\n",
        "def fd(description: str, **kwargs):\n",
        "    return Field(description=description, **kwargs)\n",
        "\n",
        "\n",
        "# https://stackoverflow.com/a/58938747\n",
        "def remove_a_key(d, remove_key):\n",
        "    if isinstance(d, dict):\n",
        "        for key in list(d.keys()):\n",
        "            if key == remove_key:\n",
        "                del d[key]\n",
        "            else:\n",
        "                remove_a_key(d[key], remove_key)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import datetime\n",
        "from uuid import uuid4, UUID\n",
        "\n",
        "from pydantic import BaseModel, SecretStr, HttpUrl, Field\n",
        "from typing import List, Dict, Union, Optional, Set, Any\n",
        "import orjson\n",
        "\n",
        "\n",
        "def orjson_dumps(v, *, default, **kwargs):\n",
        "    # orjson.dumps returns bytes, to match standard json.dumps we need to decode\n",
        "    return orjson.dumps(v, default=default, **kwargs).decode()\n",
        "\n",
        "\n",
        "def now_tz():\n",
        "    # Need datetime w/ timezone for cleanliness\n",
        "    # https://stackoverflow.com/a/24666683\n",
        "    return datetime.datetime.now(datetime.timezone.utc)\n",
        "\n",
        "\n",
        "class ChatMessage(BaseModel):\n",
        "    role: str\n",
        "    content: str\n",
        "    name: Optional[str] = None\n",
        "    function_call: Optional[str] = None\n",
        "    received_at: datetime.datetime = Field(default_factory=now_tz)\n",
        "    finish_reason: Optional[str] = None\n",
        "    prompt_length: Optional[int] = None\n",
        "    completion_length: Optional[int] = None\n",
        "    total_length: Optional[int] = None\n",
        "\n",
        "    def __str__(self) -> str:\n",
        "        return str(self.model_dump(exclude_none=True))\n",
        "\n",
        "\n",
        "class ChatSession(BaseModel):\n",
        "    id: Union[str, UUID] = Field(default_factory=uuid4)\n",
        "    created_at: datetime.datetime = Field(default_factory=now_tz)\n",
        "    auth: Dict[str, SecretStr]\n",
        "    api_url: HttpUrl\n",
        "    model: str\n",
        "    system: str\n",
        "    params: Dict[str, Any] = {}\n",
        "    messages: List[ChatMessage] = []\n",
        "    input_fields: Set[str] = {}\n",
        "    recent_messages: Optional[int] = None\n",
        "    save_messages: Optional[bool] = True\n",
        "    total_prompt_length: int = 0\n",
        "    total_completion_length: int = 0\n",
        "    total_length: int = 0\n",
        "    title: Optional[str] = None\n",
        "\n",
        "    def __str__(self) -> str:\n",
        "        sess_start_str = self.created_at.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "        last_message_str = self.messages[-1].received_at.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "        return f\"\"\"Chat session started at {sess_start_str}:\n",
        "        - {len(self.messages):,} Messages\n",
        "        - Last message sent at {last_message_str}\"\"\"\n",
        "\n",
        "    def format_input_messages(\n",
        "        self, system_message: ChatMessage, user_message: ChatMessage\n",
        "    ) -> list:\n",
        "        recent_messages = (\n",
        "            self.messages[-self.recent_messages :]\n",
        "            if self.recent_messages\n",
        "            else self.messages\n",
        "        )\n",
        "        return (\n",
        "            [system_message.model_dump(include=self.input_fields, exclude_none=True)]\n",
        "            + [\n",
        "                m.model_dump(include=self.input_fields, exclude_none=True)\n",
        "                for m in recent_messages\n",
        "            ]\n",
        "            + [user_message.model_dump(include=self.input_fields, exclude_none=True)]\n",
        "        )\n",
        "\n",
        "    def add_messages(\n",
        "        self,\n",
        "        user_message: ChatMessage,\n",
        "        assistant_message: ChatMessage,\n",
        "        save_messages: bool = None,\n",
        "    ) -> None:\n",
        "\n",
        "        # if save_messages is explicitly defined, always use that choice\n",
        "        # instead of the default\n",
        "        to_save = isinstance(save_messages, bool)\n",
        "\n",
        "        print(\"DEBUG: add_messages\")\n",
        "        print('user: ')\n",
        "        print( user_message)\n",
        "        print('assistant: ')\n",
        "        print( assistant_message)\n",
        "\n",
        "        if to_save:\n",
        "            if save_messages:\n",
        "                self.messages.append(user_message)\n",
        "                self.messages.append(assistant_message)\n",
        "        elif self.save_messages:\n",
        "            self.messages.append(user_message)\n",
        "            self.messages.append(assistant_message)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from pydantic import HttpUrl\n",
        "from httpx import Client, AsyncClient\n",
        "from typing import List, Dict, Union, Set, Any\n",
        "import orjson\n",
        "\n",
        "\n",
        "\n",
        "tool_prompt = \"\"\"From the list of tools below:\n",
        "- Reply ONLY with the number of the tool appropriate in response to the user's last message.\n",
        "- If no tool is appropriate, ONLY reply with \\\"0\\\".\n",
        "\n",
        "{tools}\"\"\"\n",
        "\n",
        "\n",
        "class ChatGPTSession(ChatSession):\n",
        "    api_url: HttpUrl = \"https://api.openai.com/v1/chat/completions\"\n",
        "    input_fields: Set[str] = {\"role\", \"content\", \"name\"}\n",
        "    system: str = \"You are a helpful assistant.\"\n",
        "    params: Dict[str, Any] = {\"temperature\": 0.7}\n",
        "\n",
        "    def prepare_request(\n",
        "        self,\n",
        "        prompt: str,\n",
        "        system: str = None,\n",
        "        params: Dict[str, Any] = None,\n",
        "        stream: bool = False,\n",
        "        input_schema: Any = None,\n",
        "        output_schema: Any = None,\n",
        "        is_function_calling_required: bool = True,\n",
        "    ):\n",
        "        headers = {\n",
        "            \"Content-Type\": \"application/json\",\n",
        "            \"Authorization\": f\"Bearer {self.auth['api_key'].get_secret_value()}\",\n",
        "        }\n",
        "\n",
        "        system_message = ChatMessage(role=\"system\", content=system or self.system)\n",
        "        if not input_schema:\n",
        "            user_message = ChatMessage(role=\"user\", content=prompt)\n",
        "        else:\n",
        "            assert isinstance(\n",
        "                prompt, input_schema\n",
        "            ), f\"prompt must be an instance of {input_schema.__name__}\"\n",
        "            user_message = ChatMessage(\n",
        "                role=\"function\",\n",
        "                content=prompt.model_dump_json(),\n",
        "                name=input_schema.__name__,\n",
        "            )\n",
        "\n",
        "        gen_params = params or self.params\n",
        "        data = {\n",
        "            \"model\": self.model,\n",
        "            \"messages\": self.format_input_messages(system_message, user_message),\n",
        "            \"stream\": stream,\n",
        "            **gen_params,\n",
        "        }\n",
        "\n",
        "        # Add function calling parameters if a schema is provided\n",
        "        if input_schema or output_schema:\n",
        "            functions = []\n",
        "            if input_schema:\n",
        "                input_function = self.schema_to_function(input_schema)\n",
        "                functions.append(input_function)\n",
        "            if output_schema:\n",
        "                output_function = self.schema_to_function(output_schema)\n",
        "                functions.append(\n",
        "                    output_function\n",
        "                ) if output_function not in functions else None\n",
        "                if is_function_calling_required:\n",
        "                    data[\"function_call\"] = {\"name\": output_schema.__name__}\n",
        "            data[\"functions\"] = functions\n",
        "\n",
        "        return headers, data, user_message\n",
        "\n",
        "    def schema_to_function(self, schema: Any):\n",
        "        assert schema.__doc__, f\"{schema.__name__} is missing a docstring.\"\n",
        "        assert (\n",
        "            \"title\" not in schema.__fields__.keys()\n",
        "        ), \"`title` is a reserved keyword and cannot be used as a field name.\"\n",
        "        schema_dict = schema.model_json_schema()\n",
        "        remove_a_key(schema_dict, \"title\")\n",
        "\n",
        "        return {\n",
        "            \"name\": schema.__name__,\n",
        "            \"description\": schema.__doc__,\n",
        "            \"parameters\": schema_dict,\n",
        "        }\n",
        "\n",
        "    def gen(\n",
        "        self,\n",
        "        prompt: str,\n",
        "        client: Union[Client, AsyncClient],\n",
        "        system: str = None,\n",
        "        save_messages: bool = None,\n",
        "        params: Dict[str, Any] = None,\n",
        "        input_schema: Any = None,\n",
        "        output_schema: Any = None,\n",
        "    ):\n",
        "        headers, data, user_message = self.prepare_request(\n",
        "            prompt, system, params, False, input_schema, output_schema\n",
        "        )\n",
        "\n",
        "        r = client.post(\n",
        "            str(self.api_url),\n",
        "            json=data,\n",
        "            headers=headers,\n",
        "            timeout=None,\n",
        "        )\n",
        "        r = r.json()\n",
        "\n",
        "        try:\n",
        "            if not output_schema:\n",
        "                content = r[\"choices\"][0][\"message\"][\"content\"]\n",
        "                assistant_message = ChatMessage(\n",
        "                    role=r[\"choices\"][0][\"message\"][\"role\"],\n",
        "                    content=content,\n",
        "                    finish_reason=r[\"choices\"][0][\"finish_reason\"],\n",
        "                    prompt_length=r[\"usage\"][\"prompt_tokens\"],\n",
        "                    completion_length=r[\"usage\"][\"completion_tokens\"],\n",
        "                    total_length=r[\"usage\"][\"total_tokens\"],\n",
        "                )\n",
        "                self.add_messages(user_message, assistant_message, save_messages)\n",
        "            else:\n",
        "                content = r[\"choices\"][0][\"message\"][\"function_call\"][\"arguments\"]\n",
        "                content = orjson.loads(content)\n",
        "\n",
        "            self.total_prompt_length += r[\"usage\"][\"prompt_tokens\"]\n",
        "            self.total_completion_length += r[\"usage\"][\"completion_tokens\"]\n",
        "            self.total_length += r[\"usage\"][\"total_tokens\"]\n",
        "        except KeyError:\n",
        "            raise KeyError(f\"No AI generation: {r}\")\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"DEBUG: gen()\")\n",
        "        print(content)\n",
        "        print(\"\")\n",
        "\n",
        "        return content\n",
        "\n",
        "    def stream(\n",
        "        self,\n",
        "        prompt: str,\n",
        "        client: Union[Client, AsyncClient],\n",
        "        system: str = None,\n",
        "        save_messages: bool = None,\n",
        "        params: Dict[str, Any] = None,\n",
        "        input_schema: Any = None,\n",
        "    ):\n",
        "        headers, data, user_message = self.prepare_request(\n",
        "            prompt, system, params, True, input_schema\n",
        "        )\n",
        "\n",
        "        with client.stream(\n",
        "            \"POST\",\n",
        "            str(self.api_url),\n",
        "            json=data,\n",
        "            headers=headers,\n",
        "            timeout=None,\n",
        "        ) as r:\n",
        "            content = []\n",
        "            for chunk in r.iter_lines():\n",
        "                if len(chunk) > 0:\n",
        "                    chunk = chunk[6:]  # SSE JSON chunks are prepended with \"data: \"\n",
        "                    if chunk != \"[DONE]\":\n",
        "                        chunk_dict = orjson.loads(chunk)\n",
        "                        delta = chunk_dict[\"choices\"][0][\"delta\"].get(\"content\")\n",
        "                        if delta:\n",
        "                            content.append(delta)\n",
        "                            yield {\"delta\": delta, \"response\": \"\".join(content)}\n",
        "\n",
        "        # streaming does not currently return token counts\n",
        "        assistant_message = ChatMessage(\n",
        "            role=\"assistant\",\n",
        "            content=\"\".join(content),\n",
        "        )\n",
        "\n",
        "        self.add_messages(user_message, assistant_message, save_messages)\n",
        "\n",
        "        return assistant_message\n",
        "\n",
        "    def gen_with_tools(\n",
        "        self,\n",
        "        prompt: str,\n",
        "        tools: List[Any],\n",
        "        client: Union[Client, AsyncClient],\n",
        "        system: str = None,\n",
        "        save_messages: bool = None,\n",
        "        params: Dict[str, Any] = None,\n",
        "    ) -> Dict[str, Any]:\n",
        "\n",
        "        # call 1: select tool and populate context\n",
        "        tools_list = \"\\n\".join(f\"{i+1}: {f.__doc__}\" for i, f in enumerate(tools))\n",
        "        tool_prompt_format = tool_prompt.format(tools=tools_list)\n",
        "\n",
        "        logit_bias_weight = 100\n",
        "        logit_bias = {str(k): logit_bias_weight for k in range(15, 15 + len(tools) + 1)}\n",
        "\n",
        "        tool_idx = int(\n",
        "            self.gen(\n",
        "                prompt,\n",
        "                client=client,\n",
        "                system=tool_prompt_format,\n",
        "                save_messages=False,\n",
        "                params={\n",
        "                    \"temperature\": 0.0,\n",
        "                    \"max_tokens\": 1,\n",
        "                    \"logit_bias\": logit_bias,\n",
        "                },\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # if no tool is selected, do a standard generation instead.\n",
        "        if tool_idx == 0:\n",
        "            return {\n",
        "                \"response\": self.gen(\n",
        "                    prompt,\n",
        "                    client=client,\n",
        "                    system=system,\n",
        "                    save_messages=save_messages,\n",
        "                    params=params,\n",
        "                ),\n",
        "                \"tool\": None,\n",
        "            }\n",
        "        selected_tool = tools[tool_idx - 1]\n",
        "        context_dict = selected_tool(prompt)\n",
        "        if isinstance(context_dict, str):\n",
        "            context_dict = {\"context\": context_dict}\n",
        "\n",
        "        context_dict[\"tool\"] = selected_tool.__name__\n",
        "\n",
        "        # call 2: generate from the context\n",
        "        new_system = f\"{system or self.system}\\n\\nYou MUST use information from the context in your response.\"\n",
        "        new_prompt = f\"Context: {context_dict['context']}\\n\\nUser: {prompt}\"\n",
        "\n",
        "        context_dict[\"response\"] = self.gen(\n",
        "            new_prompt,\n",
        "            client=client,\n",
        "            system=new_system,\n",
        "            save_messages=False,\n",
        "            params=params,\n",
        "        )\n",
        "\n",
        "        # manually append the nonmodified user message + normal AI response\n",
        "        user_message = ChatMessage(role=\"user\", content=prompt)\n",
        "        assistant_message = ChatMessage(\n",
        "            role=\"assistant\", content=context_dict[\"response\"]\n",
        "        )\n",
        "        self.add_messages(user_message, assistant_message, save_messages)\n",
        "\n",
        "        return context_dict\n",
        "\n",
        "    async def gen_async(\n",
        "        self,\n",
        "        prompt: str,\n",
        "        client: Union[Client, AsyncClient],\n",
        "        system: str = None,\n",
        "        save_messages: bool = None,\n",
        "        params: Dict[str, Any] = None,\n",
        "        input_schema: Any = None,\n",
        "        output_schema: Any = None,\n",
        "    ):\n",
        "        headers, data, user_message = self.prepare_request(\n",
        "            prompt, system, params, False, input_schema, output_schema\n",
        "        )\n",
        "\n",
        "        r = await client.post(\n",
        "            str(self.api_url),\n",
        "            json=data,\n",
        "            headers=headers,\n",
        "            timeout=None,\n",
        "        )\n",
        "        r = r.json()\n",
        "\n",
        "        try:\n",
        "            if not output_schema:\n",
        "                content = r[\"choices\"][0][\"message\"][\"content\"]\n",
        "                assistant_message = ChatMessage(\n",
        "                    role=r[\"choices\"][0][\"message\"][\"role\"],\n",
        "                    content=content,\n",
        "                    finish_reason=r[\"choices\"][0][\"finish_reason\"],\n",
        "                    prompt_length=r[\"usage\"][\"prompt_tokens\"],\n",
        "                    completion_length=r[\"usage\"][\"completion_tokens\"],\n",
        "                    total_length=r[\"usage\"][\"total_tokens\"],\n",
        "                )\n",
        "                self.add_messages(user_message, assistant_message, save_messages)\n",
        "            else:\n",
        "                content = r[\"choices\"][0][\"message\"][\"function_call\"][\"arguments\"]\n",
        "                content = orjson.loads(content)\n",
        "\n",
        "            self.total_prompt_length += r[\"usage\"][\"prompt_tokens\"]\n",
        "            self.total_completion_length += r[\"usage\"][\"completion_tokens\"]\n",
        "            self.total_length += r[\"usage\"][\"total_tokens\"]\n",
        "        except KeyError:\n",
        "            raise KeyError(f\"No AI generation: {r}\")\n",
        "\n",
        "        return content\n",
        "\n",
        "    async def stream_async(\n",
        "        self,\n",
        "        prompt: str,\n",
        "        client: Union[Client, AsyncClient],\n",
        "        system: str = None,\n",
        "        save_messages: bool = None,\n",
        "        params: Dict[str, Any] = None,\n",
        "        input_schema: Any = None,\n",
        "    ):\n",
        "        headers, data, user_message = self.prepare_request(\n",
        "            prompt, system, params, True, input_schema\n",
        "        )\n",
        "\n",
        "        async with client.stream(\n",
        "            \"POST\",\n",
        "            str(self.api_url),\n",
        "            json=data,\n",
        "            headers=headers,\n",
        "            timeout=None,\n",
        "        ) as r:\n",
        "            content = []\n",
        "            async for chunk in r.aiter_lines():\n",
        "                if len(chunk) > 0:\n",
        "                    chunk = chunk[6:]  # SSE JSON chunks are prepended with \"data: \"\n",
        "                    if chunk != \"[DONE]\":\n",
        "                        chunk_dict = orjson.loads(chunk)\n",
        "                        delta = chunk_dict[\"choices\"][0][\"delta\"].get(\"content\")\n",
        "                        if delta:\n",
        "                            content.append(delta)\n",
        "                            yield {\"delta\": delta, \"response\": \"\".join(content)}\n",
        "\n",
        "        # streaming does not currently return token counts\n",
        "        assistant_message = ChatMessage(\n",
        "            role=\"assistant\",\n",
        "            content=\"\".join(content),\n",
        "        )\n",
        "\n",
        "        self.add_messages(user_message, assistant_message, save_messages)\n",
        "\n",
        "    async def gen_with_tools_async(\n",
        "        self,\n",
        "        prompt: str,\n",
        "        tools: List[Any],\n",
        "        client: Union[Client, AsyncClient],\n",
        "        system: str = None,\n",
        "        save_messages: bool = None,\n",
        "        params: Dict[str, Any] = None,\n",
        "    ) -> Dict[str, Any]:\n",
        "\n",
        "        # call 1: select tool and populate context\n",
        "        tools_list = \"\\n\".join(f\"{i+1}: {f.__doc__}\" for i, f in enumerate(tools))\n",
        "        tool_prompt_format = tool_prompt.format(tools=tools_list)\n",
        "\n",
        "        logit_bias_weight = 100\n",
        "        logit_bias = {str(k): logit_bias_weight for k in range(15, 15 + len(tools) + 1)}\n",
        "\n",
        "        tool_idx = int(\n",
        "            await self.gen_async(\n",
        "                prompt,\n",
        "                client=client,\n",
        "                system=tool_prompt_format,\n",
        "                save_messages=False,\n",
        "                params={\n",
        "                    \"temperature\": 0.0,\n",
        "                    \"max_tokens\": 1,\n",
        "                    \"logit_bias\": logit_bias,\n",
        "                },\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # if no tool is selected, do a standard generation instead.\n",
        "        if tool_idx == 0:\n",
        "            return {\n",
        "                \"response\": await self.gen_async(\n",
        "                    prompt,\n",
        "                    client=client,\n",
        "                    system=system,\n",
        "                    save_messages=save_messages,\n",
        "                    params=params,\n",
        "                ),\n",
        "                \"tool\": None,\n",
        "            }\n",
        "        selected_tool = tools[tool_idx - 1]\n",
        "        context_dict = await selected_tool(prompt)\n",
        "        if isinstance(context_dict, str):\n",
        "            context_dict = {\"context\": context_dict}\n",
        "\n",
        "        context_dict[\"tool\"] = selected_tool.__name__\n",
        "\n",
        "        # call 2: generate from the context\n",
        "        new_system = f\"{system or self.system}\\n\\nYou MUST use information from the context in your response.\"\n",
        "        new_prompt = f\"Context: {context_dict['context']}\\n\\nUser: {prompt}\"\n",
        "\n",
        "        context_dict[\"response\"] = await self.gen_async(\n",
        "            new_prompt,\n",
        "            client=client,\n",
        "            system=new_system,\n",
        "            save_messages=False,\n",
        "            params=params,\n",
        "        )\n",
        "\n",
        "        # manually append the nonmodified user message + normal AI response\n",
        "        user_message = ChatMessage(role=\"user\", content=prompt)\n",
        "        assistant_message = ChatMessage(\n",
        "            role=\"assistant\", content=context_dict[\"response\"]\n",
        "        )\n",
        "        self.add_messages(user_message, assistant_message, save_messages)\n",
        "\n",
        "        return context_dict\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "\n",
        "class AIChat(BaseModel):\n",
        "    client: Any\n",
        "    default_session: Optional[ChatSession]\n",
        "    sessions: Dict[Union[str, UUID], ChatSession] = {}\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        character: str = None,\n",
        "        character_command: str = None,\n",
        "        system: str = None,\n",
        "        id: Union[str, UUID] = uuid4(),\n",
        "        prime: bool = True,\n",
        "        default_session: bool = True,\n",
        "        console: bool = True,\n",
        "        **kwargs,\n",
        "    ):\n",
        "\n",
        "        client = Client(proxies=os.getenv(\"https_proxy\"))\n",
        "        system_format = self.build_system(character, character_command, system)\n",
        "\n",
        "        sessions = {}\n",
        "        new_default_session = None\n",
        "        if default_session:\n",
        "            new_session = self.new_session(\n",
        "                return_session=True, system=system_format, id=id, **kwargs\n",
        "            )\n",
        "\n",
        "            new_default_session = new_session\n",
        "            sessions = {new_session.id: new_session}\n",
        "\n",
        "        super().__init__(\n",
        "            client=client, default_session=new_default_session, sessions=sessions\n",
        "        )\n",
        "\n",
        "        if not system and console:\n",
        "            character = \"ChatGPT\" if not character else character\n",
        "            new_default_session.title = character\n",
        "            self.interactive_console(character=character, prime=prime)\n",
        "\n",
        "    def new_session(\n",
        "        self,\n",
        "        return_session: bool = False,\n",
        "        **kwargs,\n",
        "    ) -> Optional[ChatGPTSession]:\n",
        "\n",
        "        if \"model\" not in kwargs:  # set default\n",
        "            kwargs[\"model\"] = \"gpt-3.5-turbo\"\n",
        "        # TODO: Add support for more models (PaLM, Claude)\n",
        "        if \"gpt-\" in kwargs[\"model\"]:\n",
        "            gpt_api_key = kwargs.get(\"api_key\") or os.getenv(\"OPENAI_API_KEY\")\n",
        "            assert gpt_api_key, f\"An API key for {kwargs['model'] } was not defined.\"\n",
        "            sess = ChatGPTSession(\n",
        "                auth={\n",
        "                    \"api_key\": gpt_api_key,\n",
        "                },\n",
        "                **kwargs,\n",
        "            )\n",
        "\n",
        "        if return_session:\n",
        "            return sess\n",
        "        else:\n",
        "            self.sessions[sess.id] = sess\n",
        "\n",
        "    def get_session(self, id: Union[str, UUID] = None) -> ChatSession:\n",
        "        try:\n",
        "            sess = self.sessions[id] if id else self.default_session\n",
        "        except KeyError:\n",
        "            raise KeyError(\"No session by that key exists.\")\n",
        "        if not sess:\n",
        "            raise ValueError(\"No default session exists.\")\n",
        "        return sess\n",
        "\n",
        "    def reset_session(self, id: Union[str, UUID] = None) -> None:\n",
        "        sess = self.get_session(id)\n",
        "        sess.messages = []\n",
        "\n",
        "    def delete_session(self, id: Union[str, UUID] = None) -> None:\n",
        "        sess = self.get_session(id)\n",
        "        if self.default_session:\n",
        "            if sess.id == self.default_session.id:\n",
        "                self.default_session = None\n",
        "        del self.sessions[sess.id]\n",
        "        del sess\n",
        "\n",
        "    @contextmanager\n",
        "    def session(self, **kwargs):\n",
        "        sess = self.new_session(return_session=True, **kwargs)\n",
        "        self.sessions[sess.id] = sess\n",
        "        try:\n",
        "            yield sess\n",
        "        finally:\n",
        "            self.delete_session(sess.id)\n",
        "\n",
        "    def __call__(\n",
        "        self,\n",
        "        prompt: Union[str, Any],\n",
        "        id: Union[str, UUID] = None,\n",
        "        system: str = None,\n",
        "        save_messages: bool = None,\n",
        "        params: Dict[str, Any] = None,\n",
        "        tools: List[Any] = None,\n",
        "        input_schema: Any = None,\n",
        "        output_schema: Any = None,\n",
        "    ) -> str:\n",
        "        sess = self.get_session(id)\n",
        "        if tools:\n",
        "            for tool in tools:\n",
        "                assert tool.__doc__, f\"Tool {tool} does not have a docstring.\"\n",
        "            assert len(tools) <= 9, \"You can only have a maximum of 9 tools.\"\n",
        "            return sess.gen_with_tools(\n",
        "                prompt,\n",
        "                tools,\n",
        "                client=self.client,\n",
        "                system=system,\n",
        "                save_messages=save_messages,\n",
        "                params=params,\n",
        "            )\n",
        "        else:\n",
        "            return sess.gen(\n",
        "                prompt,\n",
        "                client=self.client,\n",
        "                system=system,\n",
        "                save_messages=save_messages,\n",
        "                params=params,\n",
        "                input_schema=input_schema,\n",
        "                output_schema=output_schema,\n",
        "            )\n",
        "\n",
        "    def stream(\n",
        "        self,\n",
        "        prompt: str,\n",
        "        id: Union[str, UUID] = None,\n",
        "        system: str = None,\n",
        "        save_messages: bool = None,\n",
        "        params: Dict[str, Any] = None,\n",
        "        input_schema: Any = None,\n",
        "    ) -> str:\n",
        "        sess = self.get_session(id)\n",
        "        return sess.stream(\n",
        "            prompt,\n",
        "            client=self.client,\n",
        "            system=system,\n",
        "            save_messages=save_messages,\n",
        "            params=params,\n",
        "            input_schema=input_schema,\n",
        "        )\n",
        "\n",
        "    def build_system(\n",
        "        self, character: str = None, character_command: str = None, system: str = None\n",
        "    ) -> str:\n",
        "        default = \"You are a helpful assistant.\"\n",
        "        if character:\n",
        "            character_prompt = \"\"\"\n",
        "            You must follow ALL these rules in all responses:\n",
        "            - You are the following character and should ALWAYS act as them: {0}\n",
        "            - NEVER speak in a formal tone.\n",
        "            - Concisely introduce yourself first in character.\n",
        "            \"\"\"\n",
        "            prompt = character_prompt.format(wikipedia_search_lookup(character)).strip()\n",
        "            if character_command:\n",
        "                character_system = \"\"\"\n",
        "                - {0}\n",
        "                \"\"\"\n",
        "                prompt = (\n",
        "                    prompt + \"\\n\" + character_system.format(character_command).strip()\n",
        "                )\n",
        "            return prompt\n",
        "        elif system:\n",
        "            return system\n",
        "        else:\n",
        "            return default\n",
        "\n",
        "    def interactive_console(self, character: str = None, prime: bool = True) -> None:\n",
        "        console = Console(highlight=False, force_jupyter=False)\n",
        "        sess = self.default_session\n",
        "        ai_text_color = \"bright_magenta\"\n",
        "\n",
        "        # prime with a unique starting response to the user\n",
        "        if prime:\n",
        "            console.print(f\"[b]{character}[/b]: \", end=\"\", style=ai_text_color)\n",
        "            for chunk in sess.stream(\"Hello!\", self.client):\n",
        "                console.print(chunk[\"delta\"], end=\"\", style=ai_text_color)\n",
        "\n",
        "        while True:\n",
        "            console.print()\n",
        "            try:\n",
        "                user_input = console.input(\"[b]You:[/b] \").strip()\n",
        "                if not user_input:\n",
        "                    break\n",
        "\n",
        "                console.print(f\"[b]{character}[/b]: \", end=\"\", style=ai_text_color)\n",
        "                for chunk in sess.stream(user_input, self.client):\n",
        "                    console.print(chunk[\"delta\"], end=\"\", style=ai_text_color)\n",
        "            except KeyboardInterrupt:\n",
        "                break\n",
        "\n",
        "    def __str__(self) -> str:\n",
        "        if self.default_session:\n",
        "            return self.default_session.model_dump_json(\n",
        "                exclude={\"api_key\", \"api_url\"},\n",
        "                exclude_none=True,\n",
        "                option=orjson.OPT_INDENT_2,\n",
        "            )\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return \"\"\n",
        "\n",
        "    # Save/Load Chats given a session id\n",
        "    def save_session(\n",
        "        self,\n",
        "        output_path: str = None,\n",
        "        id: Union[str, UUID] = None,\n",
        "        format: str = \"csv\",\n",
        "        minify: bool = False,\n",
        "    ):\n",
        "        sess = self.get_session(id)\n",
        "        sess_dict = sess.model_dump(\n",
        "            exclude={\"auth\", \"api_url\", \"input_fields\"},\n",
        "            exclude_none=True,\n",
        "        )\n",
        "        output_path = output_path or f\"chat_session.{format}\"\n",
        "        if format == \"csv\":\n",
        "            with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                fields = [\n",
        "                    \"role\",\n",
        "                    \"content\",\n",
        "                    \"received_at\",\n",
        "                    \"prompt_length\",\n",
        "                    \"completion_length\",\n",
        "                    \"total_length\",\n",
        "                ]\n",
        "                w = csv.DictWriter(f, fieldnames=fields)\n",
        "                w.writeheader()\n",
        "                for message in sess_dict[\"messages\"]:\n",
        "                    # datetime must be in common format to be loaded into spreadsheet\n",
        "                    # for human-readability, the timezone is set to local machine\n",
        "                    local_datetime = message[\"received_at\"].astimezone()\n",
        "                    message[\"received_at\"] = local_datetime.strftime(\n",
        "                        \"%Y-%m-%d %H:%M:%S\"\n",
        "                    )\n",
        "                    w.writerow(message)\n",
        "        elif format == \"json\":\n",
        "            with open(output_path, \"wb\") as f:\n",
        "                f.write(\n",
        "                    orjson.dumps(\n",
        "                        sess_dict, option=orjson.OPT_INDENT_2 if not minify else None\n",
        "                    )\n",
        "                )\n",
        "\n",
        "    def load_session(self, input_path: str, id: Union[str, UUID] = uuid4(), **kwargs):\n",
        "\n",
        "        assert input_path.endswith(\".csv\") or input_path.endswith(\n",
        "            \".json\"\n",
        "        ), \"Only CSV and JSON imports are accepted.\"\n",
        "\n",
        "        if input_path.endswith(\".csv\"):\n",
        "            with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                r = csv.DictReader(f)\n",
        "                messages = []\n",
        "                for row in r:\n",
        "                    # need to convert the datetime back to UTC\n",
        "                    local_datetime = datetime.datetime.strptime(\n",
        "                        row[\"received_at\"], \"%Y-%m-%d %H:%M:%S\"\n",
        "                    ).replace(tzinfo=dateutil.tz.tzlocal())\n",
        "                    row[\"received_at\"] = local_datetime.astimezone(\n",
        "                        datetime.timezone.utc\n",
        "                    )\n",
        "                    # https://stackoverflow.com/a/68305271\n",
        "                    row = {k: (None if v == \"\" else v) for k, v in row.items()}\n",
        "                    messages.append(ChatMessage(**row))\n",
        "\n",
        "            self.new_session(id=id, **kwargs)\n",
        "            self.sessions[id].messages = messages\n",
        "\n",
        "        if input_path.endswith(\".json\"):\n",
        "            with open(input_path, \"rb\") as f:\n",
        "                sess_dict = orjson.loads(f.read())\n",
        "            # update session with info not loaded, e.g. auth/api_url\n",
        "            for arg in kwargs:\n",
        "                sess_dict[arg] = kwargs[arg]\n",
        "            self.new_session(**sess_dict)\n",
        "\n",
        "    # Tabulators for returning total token counts\n",
        "    def message_totals(self, attr: str, id: Union[str, UUID] = None) -> int:\n",
        "        sess = self.get_session(id)\n",
        "        return getattr(sess, attr)\n",
        "\n",
        "    @property\n",
        "    def total_prompt_length(self, id: Union[str, UUID] = None) -> int:\n",
        "        return self.message_totals(\"total_prompt_length\", id)\n",
        "\n",
        "    @property\n",
        "    def total_completion_length(self, id: Union[str, UUID] = None) -> int:\n",
        "        return self.message_totals(\"total_completion_length\", id)\n",
        "\n",
        "    @property\n",
        "    def total_length(self, id: Union[str, UUID] = None) -> int:\n",
        "        return self.message_totals(\"total_length\", id)\n",
        "\n",
        "    # alias total_tokens to total_length for common use\n",
        "    @property\n",
        "    def total_tokens(self, id: Union[str, UUID] = None) -> int:\n",
        "        return self.total_length(id)\n",
        "\n",
        "\n",
        "class AsyncAIChat(AIChat):\n",
        "    async def __call__(\n",
        "        self,\n",
        "        prompt: str,\n",
        "        id: Union[str, UUID] = None,\n",
        "        system: str = None,\n",
        "        save_messages: bool = None,\n",
        "        params: Dict[str, Any] = None,\n",
        "        tools: List[Any] = None,\n",
        "        input_schema: Any = None,\n",
        "        output_schema: Any = None,\n",
        "    ) -> str:\n",
        "        # TODO: move to a __post_init__ in Pydantic 2.0\n",
        "        if isinstance(self.client, Client):\n",
        "            self.client = AsyncClient(proxies=os.getenv(\"https_proxy\"))\n",
        "        sess = self.get_session(id)\n",
        "        if tools:\n",
        "            for tool in tools:\n",
        "                assert tool.__doc__, f\"Tool {tool} does not have a docstring.\"\n",
        "            assert len(tools) <= 9, \"You can only have a maximum of 9 tools.\"\n",
        "            return await sess.gen_with_tools_async(\n",
        "                prompt,\n",
        "                tools,\n",
        "                client=self.client,\n",
        "                system=system,\n",
        "                save_messages=save_messages,\n",
        "                params=params,\n",
        "            )\n",
        "        else:\n",
        "            return await sess.gen_async(\n",
        "                prompt,\n",
        "                client=self.client,\n",
        "                system=system,\n",
        "                save_messages=save_messages,\n",
        "                params=params,\n",
        "                input_schema=input_schema,\n",
        "                output_schema=output_schema,\n",
        "            )\n",
        "\n",
        "    async def stream(\n",
        "        self,\n",
        "        prompt: str,\n",
        "        id: Union[str, UUID] = None,\n",
        "        system: str = None,\n",
        "        save_messages: bool = None,\n",
        "        params: Dict[str, Any] = None,\n",
        "        input_schema: Any = None,\n",
        "    ) -> str:\n",
        "        # TODO: move to a __post_init__ in Pydantic 2.0\n",
        "        if isinstance(self.client, Client):\n",
        "            self.client = AsyncClient(proxies=os.getenv(\"https_proxy\"))\n",
        "        sess = self.get_session(id)\n",
        "        return sess.stream_async(\n",
        "            prompt,\n",
        "            client=self.client,\n",
        "            system=system,\n",
        "            save_messages=save_messages,\n",
        "            params=params,\n",
        "            input_schema=input_schema,\n",
        "        )\n",
        "\n",
        "    @asynccontextmanager\n",
        "    async def session(self, **kwargs):\n",
        "        sess = self.new_session(return_session=True, **kwargs)\n",
        "        self.sessions[sess.id] = sess\n",
        "        try:\n",
        "            yield sess\n",
        "        finally:\n",
        "            self.delete_session(sess.id)"
      ],
      "metadata": {
        "id": "mp-PVysKB7HF"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from simpleaichat import AIChat\n",
        "#from simpleaichat.utils import wikipedia_search, wikipedia_search_lookup"
      ],
      "metadata": {
        "id": "-kemVh-wMfwO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ai_key = \"sk-\" # web\n",
        "#with open(\".env\", \"w\") as f:\n",
        "#    f.write(\"OPENAI_API_KEY = \" + ai_key)\n",
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = ai_key\n",
        "\n",
        "#from simpleaichat import AIChat\n",
        "#from simpleaichat.utils import wikipedia_search, wikipedia_search_lookup"
      ],
      "metadata": {
        "id": "xWhGwpn909cI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#AIChat(api_key=\"sk-KEY...\", model=\"gpt-3.5-turbo\") # Web Key\n",
        "AIChat(model=\"gpt-3.5-turbo\") # \"gpt-4\""
      ],
      "metadata": {
        "id": "HyKzxWKHyMfJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "283e5d76-45ca-41d5-a534-7c72d68bcd9e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatGPT: Hello! How can I assist you today?DEBUG: add_messages\n",
            "\n",
            "You: "
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tool Test 1\n",
        "\n",
        "- Im Beispiel sind 2 Tools definiert: `search(query)` und `lookup(query)`\n",
        "- Die Beschreibung im Docstring `\"\"\"Search the internet.\"\"` wird im Prompt verwendet, um das passende Tool herauszusuchen. Der Docstring ist daher zwingend notwendig, sonst wird mit einem Fehler abgebrochen\n"
      ],
      "metadata": {
        "id": "cX_n3DptInqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This uses the Wikipedia Search API.\n",
        "# Results from it are nondeterministic, your mileage will vary.\n",
        "def search(query):\n",
        "    \"\"\"Search the internet.\"\"\"\n",
        "    wiki_matches = wikipedia_search(query, n=3)\n",
        "    return {\"context\": \", \".join(wiki_matches), \"titles\": wiki_matches}\n",
        "\n",
        "def lookup(query):\n",
        "    \"\"\"Lookup more information about a topic.\"\"\"\n",
        "    page = wikipedia_search_lookup(query, sentences=3)\n",
        "    return page\n",
        "\n",
        "params = {\"temperature\": 0.0, \"max_tokens\": 100}\n",
        "ai = AIChat(params=params, console=False)\n",
        "\n",
        "ai(\"Touristenattraktionen in Köln\", tools=[search, lookup])"
      ],
      "metadata": {
        "id": "6uLPVjAa2qms",
        "outputId": "39f244e4-18e0-41b3-c768-9b9f5d24867b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEBUG: add_messages\n",
            "user: \n",
            "{'role': 'user', 'content': 'Touristenattraktionen in Köln', 'received_at': datetime.datetime(2023, 9, 22, 18, 33, 28, 694458, tzinfo=datetime.timezone.utc)}\n",
            "assistant: \n",
            "{'role': 'assistant', 'content': '1', 'received_at': datetime.datetime(2023, 9, 22, 18, 33, 29, 279345, tzinfo=datetime.timezone.utc), 'finish_reason': 'length', 'prompt_length': 73, 'completion_length': 1, 'total_length': 74}\n",
            "\n",
            "DEBUG: gen()\n",
            "1\n",
            "\n",
            "DEBUG: add_messages\n",
            "user: \n",
            "{'role': 'user', 'content': 'Context: \\n\\nUser: Touristenattraktionen in Köln', 'received_at': datetime.datetime(2023, 9, 22, 18, 33, 29, 606985, tzinfo=datetime.timezone.utc)}\n",
            "assistant: \n",
            "{'role': 'assistant', 'content': 'Assistant: In Köln gibt es viele Touristenattraktionen, die Sie besuchen können. Eine der bekanntesten Sehenswürdigkeiten ist der Kölner Dom. Dieses beeindruckende gotische Bauwerk ist nicht nur das Wahrzeichen der Stadt, sondern auch eine der größten Kathedralen der Welt. Sie können den Dom besichtigen und sogar den Turm besteigen, um einen atemberaubenden Blick über die Stadt zu genießen', 'received_at': datetime.datetime(2023, 9, 22, 18, 33, 34, 800317, tzinfo=datetime.timezone.utc), 'finish_reason': 'length', 'prompt_length': 41, 'completion_length': 100, 'total_length': 141}\n",
            "\n",
            "DEBUG: gen()\n",
            "Assistant: In Köln gibt es viele Touristenattraktionen, die Sie besuchen können. Eine der bekanntesten Sehenswürdigkeiten ist der Kölner Dom. Dieses beeindruckende gotische Bauwerk ist nicht nur das Wahrzeichen der Stadt, sondern auch eine der größten Kathedralen der Welt. Sie können den Dom besichtigen und sogar den Turm besteigen, um einen atemberaubenden Blick über die Stadt zu genießen\n",
            "\n",
            "DEBUG: add_messages\n",
            "user: \n",
            "{'role': 'user', 'content': 'Touristenattraktionen in Köln', 'received_at': datetime.datetime(2023, 9, 22, 18, 33, 34, 801384, tzinfo=datetime.timezone.utc)}\n",
            "assistant: \n",
            "{'role': 'assistant', 'content': 'Assistant: In Köln gibt es viele Touristenattraktionen, die Sie besuchen können. Eine der bekanntesten Sehenswürdigkeiten ist der Kölner Dom. Dieses beeindruckende gotische Bauwerk ist nicht nur das Wahrzeichen der Stadt, sondern auch eine der größten Kathedralen der Welt. Sie können den Dom besichtigen und sogar den Turm besteigen, um einen atemberaubenden Blick über die Stadt zu genießen', 'received_at': datetime.datetime(2023, 9, 22, 18, 33, 34, 801396, tzinfo=datetime.timezone.utc)}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'context': '',\n",
              " 'titles': [],\n",
              " 'tool': 'search',\n",
              " 'response': 'Assistant: In Köln gibt es viele Touristenattraktionen, die Sie besuchen können. Eine der bekanntesten Sehenswürdigkeiten ist der Kölner Dom. Dieses beeindruckende gotische Bauwerk ist nicht nur das Wahrzeichen der Stadt, sondern auch eine der größten Kathedralen der Welt. Sie können den Dom besichtigen und sogar den Turm besteigen, um einen atemberaubenden Blick über die Stadt zu genießen'}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(wikipedia_search(\"low code\", n=9))\n",
        "wikipedia_search_lookup(\"low code\", sentences=5)"
      ],
      "metadata": {
        "id": "YmyxuGquJvr2",
        "outputId": "9205b5c6-135a-42ed-9587-ec734f462254",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Low-code development platform', 'Low-density parity-check code', 'No-code development platform', 'Low-level programming language', 'List of low-code development platforms', 'Fourth-generation programming language', 'Error correction code', 'Automated machine learning', 'Appian Corporation']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"A low-code development platform (LCDP) provides a development environment used to create application software through a graphical user interface. A low-coded platform may produce entirely operational applications, or require additional coding for specific situations. Low-code development platforms can reduce the amount of traditional time spent, enabling accelerated delivery of business applications. A common benefit is that a wider range of people can contribute to the application's development—not only those with coding skills but require good governance to be able to adhere to common rules and regulations. LCDPs can also lower the initial cost of setup, training, deployment, and maintenance.Low-code development platforms trace their roots back to fourth-generation programming language and the rapid application development tools of the 1990s and early 2000s.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from simpleaichat import AIChat\n",
        "from simpleaichat.utils import wikipedia_search, wikipedia_search_lookup\n",
        "\n",
        "def search(query):\n",
        "    \"\"\"Search the internet.\"\"\"\n",
        "    wiki_matches = wikipedia_search(query, n=3)\n",
        "    return {\"context\": \", \".join(wiki_matches), \"titles\": wiki_matches}\n",
        "\n",
        "def lookup(query):\n",
        "    \"\"\"Lookup more information about a topic.\"\"\"\n",
        "    page = wikipedia_search_lookup(query, sentences=3)\n",
        "    return page\n",
        "\n",
        "def summarizer(query):\n",
        "    \"\"\"Erstelle eine Zusammenfassung.\"\"\"\n",
        "    # mock code\n",
        "    result = \"jung und wild.\"\n",
        "    return result\n",
        "\n",
        "def calculator(query):\n",
        "    \"\"\"Do calculations and mathematical operations.\"\"\"\n",
        "    # mock code\n",
        "    result = \"666\"\n",
        "    #return {\"context\": result, \"titles\": result}\n",
        "    return result\n",
        "\n",
        "params = {\"temperature\": 0.0, \"max_tokens\": 100}\n",
        "ai = AIChat(params=params, console=False)\n",
        "\n",
        "#ai(\"Fussballvereine in Düsseldorf\", tools=[search, lookup, summarizer, calculator])\n",
        "ai(\"Fasse den folgenden Text zusammen: Hallo Welt Lorem Ipsum.\", tools=[search, lookup, summarizer, calculator])"
      ],
      "metadata": {
        "id": "9KY74z0NJZLR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMqDjzL2NpI13tLIdTy6K20",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMHqBXlXwCunXliuz2pOjvQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aknip/Langchain-etc./blob/main/Langchain-Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afIkZ1hD4RYB"
      },
      "outputs": [],
      "source": [
        "!pip install langchain langchainhub langchain_experimental openai streamlit\n",
        "!pip install google-search-results wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import Tool, AgentExecutor\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain import hub\n",
        "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain.utilities import SerpAPIWrapper, SQLDatabase, WikipediaAPIWrapper\n",
        "from langchain_experimental.sql import SQLDatabaseChain\n",
        "from langchain.tools import WikipediaQueryRun\n",
        "from langchain.agents.format_scratchpad import format_to_openai_functions\n",
        "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
        "from langchain.tools.render import format_tool_to_openai_function\n",
        "import os\n",
        "import langchain\n",
        "import openai\n",
        "import streamlit as st"
      ],
      "metadata": {
        "id": "CEhw8Ye15BgC"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download \"Chinook\" Music Sales DB\n",
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "fname = 'chinook.zip'\n",
        "url = 'https://www.sqlitetutorial.net/wp-content/uploads/2018/03/' + fname\n",
        "r = requests.get(url)\n",
        "open(fname, 'wb').write(r.content)\n",
        "zipfile.ZipFile('chinook.zip').extractall()\n",
        "assert os.path.exists('chinook.db')"
      ],
      "metadata": {
        "id": "NE6D9WvpGL1t"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "llm = ChatOpenAI(temperature=0, model='gpt-4-0613')\n",
        "search = SerpAPIWrapper(serpapi_api_key=\"\")\n",
        "db = SQLDatabase.from_uri(\"sqlite:///chinook.db\")\n",
        "db_chain = SQLDatabaseChain.from_llm(llm, db, verbose=True)\n",
        "wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
        "tools = [\n",
        "    Tool(\n",
        "        name = \"Search\",\n",
        "        func=search.run,\n",
        "        description=\"useful for when you need to answer questions about real-time events. You should ask targeted questions\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"Wikipedia\",\n",
        "        func=wikipedia.run,\n",
        "        description=\"useful for when you need to answer questions about a big picture or background of something.\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"MusicSales\",\n",
        "        func=db_chain.run,\n",
        "        description=\"useful for when you need to answer questions about mucis sales in a store. Should be strickly follow the tables info.\"\n",
        "    )\n",
        "]\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a useful assistant.\"),\n",
        "    MessagesPlaceholder(variable_name='chat_history'),\n",
        "    (\"user\", \"{input}\"),\n",
        "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "])\n",
        "\n",
        "llm_with_tools = llm.bind(\n",
        "    functions=[format_tool_to_openai_function(t) for t in tools]\n",
        ")\n",
        "\n",
        "agent = {\n",
        "    \"input\": lambda x: x[\"input\"],\n",
        "    \"agent_scratchpad\": lambda x: format_to_openai_functions(x['intermediate_steps']),\n",
        "    \"chat_history\": lambda x: x[\"chat_history\"]\n",
        "} | prompt | llm_with_tools | OpenAIFunctionsAgentOutputParser()\n",
        "\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, memory=memory)\n"
      ],
      "metadata": {
        "id": "HcePPP4M5HPE"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt = \"How many people live in the US?\"\n",
        "# prompt = \"What is the best selling song in the music store?\"\n",
        "# prompt = \"What is the cheapest album in the music store? Tell me the price.\"\n",
        "# prompt = \"What is the best selling song starting with the letter 'F' in the music store? Tell me title and artist.\"\n",
        "prompt = \"How is the weather now in Cologne? Please use Celsius as unit for temperature.\"\n",
        "response = agent_executor.invoke({\"input\": prompt})[\"output\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EA-3_QJj6tWN",
        "outputId": "ac7a98fa-a667-4142-bb63-15858d2c3d37"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `Search` with `current weather in Cologne`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m{'type': 'weather_result', 'temperature': '65', 'unit': 'Fahrenheit', 'precipitation': '1%', 'humidity': '57%', 'wind': '11 mph', 'location': 'Cologne, Germany', 'date': 'Wednesday 1:00 PM', 'weather': 'Mostly cloudy'}\u001b[0m\u001b[32;1m\u001b[1;3mThe current weather in Cologne, Germany is mostly cloudy. The temperature is approximately 18.3 degrees Celsius. The humidity is at 57% and there is a wind speed of 11 mph. The chance of precipitation is 1%.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Zsnvgf6BRaV",
        "outputId": "0be8542a-b044-4fb7-a795-9b426762793a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The current weather in Cologne, Germany is mostly cloudy. The temperature is approximately 18.3 degrees Celsius. The humidity is at 57% and there is a wind speed of 11 mph. The chance of precipitation is 1%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradio Chatbot"
      ],
      "metadata": {
        "id": "-fL3b1FXIx9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  !pip install gradio -q\n",
        "  %load_ext gradio"
      ],
      "metadata": {
        "id": "SWqv1gumJSWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_gradio_app():\n",
        "  import gradio as gr\n",
        "  import random\n",
        "  import time\n",
        "\n",
        "  # Theming\n",
        "  theme = gr.themes.Default(\n",
        "      primary_hue=\"slate\" # , radius_size=gr.themes.Size(radius_sm=\"3px\", radius_xs=\"2px\", radius_xxs=\"1px\")\n",
        "  )\n",
        "  # Styling: Change max width\n",
        "  css = \"\"\"\n",
        "    .gradio-container {max-width: 800px!important}\n",
        "    .vspacer1 {margin-top: 50px}\n",
        "  \"\"\"\n",
        "\n",
        "  with gr.Blocks(theme=theme, css=css) as demo:\n",
        "\n",
        "      gr.Markdown(\"# MyApp\", elem_classes=\"vspacer1\")\n",
        "      gr.Markdown(\"### Optimizing your work with LLMs.\")\n",
        "\n",
        "\n",
        "      #\n",
        "      # 1. Tab 1\n",
        "      #\n",
        "      with gr.Tab(\"Chat\"):\n",
        "        # https://www.gradio.app/docs/chatbot\n",
        "\n",
        "        chatbot = gr.Chatbot(bubble_full_width=False)\n",
        "        msg = gr.Textbox()\n",
        "        clear = gr.ClearButton([msg, chatbot])\n",
        "\n",
        "\n",
        "        def respond(message, chat_history):\n",
        "            bot_message = random.choice([\"How are you?\", \"I love you\", \"I'm very hungry\"])\n",
        "            chat_history.append((message, bot_message))\n",
        "            #time.sleep(2)\n",
        "            return \"\", chat_history\n",
        "\n",
        "        def respond1(message, chat_history):\n",
        "            chat_history.append((message, None))\n",
        "            return \"\", chat_history\n",
        "\n",
        "        def respond2(chat_history):\n",
        "            bot_message = random.choice([\"How are you?\", \"I love you\", \"I'm very hungry\"])\n",
        "            chat_history.append((None, bot_message))\n",
        "            chat_history = [['hello', bot_message]] # hack\n",
        "            time.sleep(2)\n",
        "            return chat_history\n",
        "\n",
        "        #msg.submit(respond, [msg, chatbot], [msg, chatbot])\n",
        "\n",
        "\n",
        "        msg.submit(respond1, [msg, chatbot], [msg, chatbot], queue=False).then(\n",
        "          respond2, chatbot, chatbot\n",
        "        )\n",
        "\n",
        "\n",
        "      #\n",
        "      # 2. Tab 2\n",
        "      #\n",
        "      with gr.Tab(\"Input Text \"):\n",
        "        gr.Markdown(\"Please enter text\")\n",
        "\n",
        "        # Input text via UI\n",
        "        gr.Markdown(\"### Input your text:\")\n",
        "        text_input = gr.Textbox(label=\"Enter text\", placeholder=\"Your text here...\", lines=10)\n",
        "        text_output = gr.Textbox(label=\"Result\")\n",
        "\n",
        "\n",
        "      #\n",
        "      # 3. Tab 3\n",
        "      #\n",
        "      with gr.Tab(\"Step 2\"):\n",
        "        gr.Markdown(\"Please select the optimization:\")\n",
        "        radio = gr.Radio(\n",
        "          [\"by headline\", \"by paragraph\", \"by §§§\"], label=\"Text split method\"\n",
        "        )\n",
        "        name = gr.Textbox(label=\"Name\", placeholder=\"Enter text...\")\n",
        "        output = gr.Textbox(label=\"Output Box\")\n",
        "\n",
        "\n",
        "  demo.launch(quiet=True, share=False, debug=True)\n",
        "\n",
        "run_gradio_app()"
      ],
      "metadata": {
        "id": "RW6M3o8PJGYq",
        "outputId": "ff5fb04a-a4f6-445d-c476-7a35b0fe16ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7860, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tool Tests"
      ],
      "metadata": {
        "id": "ZQ02m2ARb8cO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain.tools import BaseTool, StructuredTool, Tool"
      ],
      "metadata": {
        "id": "AeaEhnYJb-LV"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"LANGCHAIN_TRACING\"] = \"true\"\n",
        "#llm = OpenAI(temperature=0)\n",
        "llm = ChatOpenAI(temperature=0, model='gpt-4-0613')"
      ],
      "metadata": {
        "id": "Zs1dGiVGcmtD"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tool 1\n",
        "def multiplier(a: float, b: float) -> float:\n",
        "    \"\"\"Multiply the provided floats.\"\"\"\n",
        "    return a * b\n",
        "\n",
        "tool = StructuredTool.from_function(multiplier)\n",
        "\n",
        "agent_executor = initialize_agent(\n",
        "    [tool],\n",
        "    llm,\n",
        "    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True,\n",
        ")\n",
        "agent_executor.run(\"What is 3 times 4\")"
      ],
      "metadata": {
        "id": "LtfgVAjZc14k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tool 2\n",
        "def calculate_insurance_premium(insured_sum: int, industry: str) -> float:\n",
        "    \"\"\"Calculate the premium for an insurance based on the maximum insured sum and the industry of the customer.\"\"\"\n",
        "    premium = insured_sum*0.25\n",
        "    return premium\n",
        "\n",
        "tool = StructuredTool.from_function(calculate_insurance_premium, return_direct=True)\n",
        "\n",
        "agent_executor = initialize_agent(\n",
        "    [tool],\n",
        "    llm,\n",
        "    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True,\n",
        ")\n",
        "agent_executor.run(\"Give me the premium for an insured sum of 10000000\")"
      ],
      "metadata": {
        "id": "dF2g6iTCdM0P",
        "outputId": "dbc3a9b3-0bf6-4751-fa31-53d5ec9e9900",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.callbacks.tracers.langchain_v1:Failed to load default session, using empty session: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sessions?name=default (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7bca605c7eb0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.callbacks.tracers.langchain_v1:Failed to persist run: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /chain-runs (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7bca605c5420>: Failed to establish a new connection: [Errno 111] Connection refused'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3mThe user has asked for the premium for an insured sum but has not provided the industry. I need to ask for the industry to be able to calculate the premium. \n",
            "\n",
            "Action:\n",
            "```\n",
            "{\n",
            "  \"action\": \"Final Answer\",\n",
            "  \"action_input\": \"Could you please specify the industry for which you want to calculate the insurance premium?\"\n",
            "}\n",
            "```\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Could you please specify the industry for which you want to calculate the insurance premium?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO8Q6ziV6JNMH7PmE5DoFwE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aknip/Langchain-etc./blob/main/Langchain-Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Langchain Agent\n",
        "\n",
        "1. Run \"Setup...\"\n",
        "2. Run one of the Agent sections\n",
        "3. Run Gradio app or CLI apps\n"
      ],
      "metadata": {
        "id": "_yJpe7D-EXzF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup for all agents and apps"
      ],
      "metadata": {
        "id": "gOMfnUf3_oTj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import psutil\n",
        "IN_NOTEBOOK = any([\"jupyter-notebook\" in i for i in psutil.Process().parent().cmdline()])"
      ],
      "metadata": {
        "id": "K_sEe-A1S56l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afIkZ1hD4RYB"
      },
      "outputs": [],
      "source": [
        "!pip install langchain langchainhub langchain_experimental openai gradio -q\n",
        "!pip install google-search-results wikipedia -q\n",
        "%load_ext gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "from getpass import getpass\n",
        "if IN_NOTEBOOK:\n",
        "  CREDS = json.loads(getpass(\"Secrets (JSON string): \"))\n",
        "  os.environ['CREDS'] = json.dumps(CREDS)\n",
        "  CREDS = json.loads(os.getenv('CREDS'))"
      ],
      "metadata": {
        "id": "IWrCvpKaENeu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import Tool, AgentExecutor\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain import hub\n",
        "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain.utilities import SerpAPIWrapper, SQLDatabase, WikipediaAPIWrapper\n",
        "from langchain_experimental.sql import SQLDatabaseChain\n",
        "from langchain.tools import WikipediaQueryRun\n",
        "from langchain.agents.format_scratchpad import format_to_openai_functions\n",
        "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
        "from langchain.tools.render import format_tool_to_openai_function\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain.tools import BaseTool, StructuredTool\n",
        "import os\n",
        "import langchain\n",
        "import openai\n",
        "import textwrap\n",
        "import gradio as gr\n",
        "import random\n",
        "import time"
      ],
      "metadata": {
        "id": "CEhw8Ye15BgC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agent 1: Wikpedia, Search, Music DB"
      ],
      "metadata": {
        "id": "eHa5SgMbz5fa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download \"Chinook\" Music Sales DB\n",
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "fname = 'chinook.zip'\n",
        "url = 'https://www.sqlitetutorial.net/wp-content/uploads/2018/03/' + fname\n",
        "r = requests.get(url)\n",
        "open(fname, 'wb').write(r.content)\n",
        "zipfile.ZipFile('chinook.zip').extractall()\n",
        "assert os.path.exists('chinook.db')"
      ],
      "metadata": {
        "id": "NE6D9WvpGL1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = CREDS['OpenAI']['v2']['credential']\n",
        "llm = ChatOpenAI(temperature=0, model='gpt-4-0613')\n",
        "search = SerpAPIWrapper(serpapi_api_key=CREDS['SERP-API']['key']['credential'])\n",
        "db = SQLDatabase.from_uri(\"sqlite:///chinook.db\")\n",
        "db_chain = SQLDatabaseChain.from_llm(llm, db, verbose=True)\n",
        "wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
        "tools = [\n",
        "    Tool(\n",
        "        name = \"Search\",\n",
        "        func=search.run,\n",
        "        description=\"useful for when you need to answer questions about real-time events. You should ask targeted questions\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"Wikipedia\",\n",
        "        func=wikipedia.run,\n",
        "        description=\"useful for when you need to answer questions about a big picture or background of something.\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"MusicSales\",\n",
        "        func=db_chain.run,\n",
        "        description=\"useful for when you need to answer questions about mucis sales in a store. Should be strickly follow the tables info.\"\n",
        "    )\n",
        "]\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a useful assistant.\"),\n",
        "    MessagesPlaceholder(variable_name='chat_history'),\n",
        "    (\"user\", \"{input}\"),\n",
        "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "])\n",
        "\n",
        "llm_with_tools = llm.bind(\n",
        "    functions=[format_tool_to_openai_function(t) for t in tools]\n",
        ")\n",
        "\n",
        "agent = {\n",
        "    \"input\": lambda x: x[\"input\"],\n",
        "    \"agent_scratchpad\": lambda x: format_to_openai_functions(x['intermediate_steps']),\n",
        "    \"chat_history\": lambda x: x[\"chat_history\"]\n",
        "} | prompt | llm_with_tools | OpenAIFunctionsAgentOutputParser()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HcePPP4M5HPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agent 2: Calculate insurance premium"
      ],
      "metadata": {
        "id": "EoYqbRg0_w19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = CREDS['OpenAI']['v2']['credential']\n",
        "llm = ChatOpenAI(temperature=0, model='gpt-4-0613')\n",
        "\n",
        "def calculate_insurance_premium(insured_sum: int, industry: str) -> float:\n",
        "    \"\"\"Calculate the premium for an insurance based on the maximum insured sum and the industry of the customer.\"\"\"\n",
        "    premium = insured_sum*0.25\n",
        "    return premium\n",
        "\n",
        "tools = [\n",
        "    StructuredTool.from_function(calculate_insurance_premium, return_direct=False)\n",
        "]\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a useful assistant.\"),\n",
        "    MessagesPlaceholder(variable_name='chat_history'),\n",
        "    (\"user\", \"{input}\"),\n",
        "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "])\n",
        "\n",
        "llm_with_tools = llm.bind(\n",
        "    functions=[format_tool_to_openai_function(t) for t in tools]\n",
        ")\n",
        "\n",
        "agent = {\n",
        "    \"input\": lambda x: x[\"input\"],\n",
        "    \"agent_scratchpad\": lambda x: format_to_openai_functions(x['intermediate_steps']),\n",
        "    \"chat_history\": lambda x: x[\"chat_history\"]\n",
        "} | prompt | llm_with_tools | OpenAIFunctionsAgentOutputParser()\n"
      ],
      "metadata": {
        "id": "vAzSbqz7_0_U"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradio Chat App for Agent"
      ],
      "metadata": {
        "id": "O_jGi0yQ-sEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, memory=memory)\n",
        "\n",
        "#\n",
        "# Gradio app\n",
        "#\n",
        "\n",
        "# Theming\n",
        "theme = gr.themes.Default(\n",
        "    primary_hue=\"slate\" # , radius_size=gr.themes.Size(radius_sm=\"3px\", radius_xs=\"2px\", radius_xxs=\"1px\")\n",
        ")\n",
        "# Styling: Change max width\n",
        "css = \"\"\"\n",
        "  .gradio-container {max-width: 800px!important}\n",
        "  .vspacer1 {margin-top: 20px}\n",
        "\"\"\"\n",
        "\n",
        "with gr.Blocks(theme=theme, css=css) as demo:\n",
        "\n",
        "    gr.Markdown(\"# Agent Chat\", elem_classes=\"vspacer1\")\n",
        "\n",
        "    with gr.Tab(\"Chat\"):\n",
        "      # https://www.gradio.app/docs/chatbot\n",
        "\n",
        "      chatbot = gr.Chatbot(bubble_full_width=False)\n",
        "      msg = gr.Textbox()\n",
        "      clear = gr.ClearButton([msg, chatbot])\n",
        "\n",
        "      # Init agent and memory\n",
        "      memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "      agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, memory=memory)\n",
        "      messages = [{\"role\": \"assistant\", \"content\": \"How can I help you?\"}]\n",
        "      #chatbot.append(None, \"How can I help you?\")\n",
        "\n",
        "      def ask(message, chat_history):\n",
        "          chat_history.append((message, None))\n",
        "          messages.append({\"role\": \"user\", \"content\": message})\n",
        "          return \"\", chat_history\n",
        "\n",
        "      def respond(chat_history):\n",
        "          prompt = chat_history[-1][0] # get prompt from history (last entry)\n",
        "          response = agent_executor.invoke({\"input\": prompt})\n",
        "          msg = {\"role\": \"assistant\", \"content\": response[\"output\"]}\n",
        "          messages.append(msg)\n",
        "          chat_history.append((None, response[\"output\"]))\n",
        "          print(\"\\n\\nMemory from response object:\")\n",
        "          print(textwrap.fill(str(response[\"chat_history\"]), 80))\n",
        "          return chat_history\n",
        "\n",
        "      msg.submit(ask, [msg, chatbot], [msg, chatbot], queue=False).then(\n",
        "        respond, chatbot, chatbot\n",
        "      )\n",
        "\n",
        "demo.launch(quiet=True, share=False, debug=True)"
      ],
      "metadata": {
        "id": "kioXkMb2-vUX",
        "outputId": "a08ec70c-3f17-4954-fe31-482575fb67ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7861, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mSure, I can help with that. However, I also need to know the industry of the customer to calculate the insurance premium. Could you please provide that information?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "Memory from response object:\n",
            "[HumanMessage(content='Give me the premium for an insured sum of 10000000'),\n",
            "AIMessage(content='Sure, I can help with that. However, I also need to know the\n",
            "industry of the customer to calculate the insurance premium. Could you please\n",
            "provide that information?')]\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `calculate_insurance_premium` with `{'insured_sum': 10000000, 'industry': 'metal construction'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m2500000.0\u001b[0m\u001b[32;1m\u001b[1;3mThe premium for an insured sum of 10,000,000 in the metal construction industry is 2,500,000.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "Memory from response object:\n",
            "[HumanMessage(content='Give me the premium for an insured sum of 10000000'),\n",
            "AIMessage(content='Sure, I can help with that. However, I also need to know the\n",
            "industry of the customer to calculate the insurance premium. Could you please\n",
            "provide that information?'), HumanMessage(content='it is metal construction'),\n",
            "AIMessage(content='The premium for an insured sum of 10,000,000 in the metal\n",
            "construction industry is 2,500,000.')]\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `calculate_insurance_premium` with `{'insured_sum': 20000000, 'industry': 'metal construction'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m5000000.0\u001b[0m\u001b[32;1m\u001b[1;3mThe premium for an insured sum of 20,000,000 in the metal construction industry is 5,000,000.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "Memory from response object:\n",
            "[HumanMessage(content='Give me the premium for an insured sum of 10000000'),\n",
            "AIMessage(content='Sure, I can help with that. However, I also need to know the\n",
            "industry of the customer to calculate the insurance premium. Could you please\n",
            "provide that information?'), HumanMessage(content='it is metal construction'),\n",
            "AIMessage(content='The premium for an insured sum of 10,000,000 in the metal\n",
            "construction industry is 2,500,000.'), HumanMessage(content='and the premium for\n",
            "an insured sum of 20000000?'), AIMessage(content='The premium for an insured sum\n",
            "of 20,000,000 in the metal construction industry is 5,000,000.')]\n",
            "Keyboard interruption in main thread... closing server.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CLI für Agent (Single Prompt)"
      ],
      "metadata": {
        "id": "dij8ZZWdbC5k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=False,  memory=memory)\n",
        "\n",
        "langchain.debug = True\n",
        "\n",
        "prompt = \"Give me the premium for an insured sum of 10000000 for metal construcion industry\"\n",
        "# prompt = \"Wie viele Menschen leben in den USA?\"\n",
        "# prompt = \"How many people live in the US?\"\n",
        "# prompt = \"What is the best selling song in the music store?\"\n",
        "# prompt = \"What is the cheapest album in the music store? Tell me the price.\"\n",
        "# prompt = \"What is the best selling song starting with the letter 'F' in the music store? Tell me title and artist.\"\n",
        "# prompt = \"How is the weather now in Cologne? Please use Celsius as unit for temperature.\"\n",
        "response = agent_executor.invoke({\"input\": prompt})\n",
        "\n",
        "# Response-Objekte:\n",
        "print()\n",
        "print(textwrap.fill(str(response[\"input\"]), 80))\n",
        "print()\n",
        "print(textwrap.fill(str(response[\"output\"]), 80))\n",
        "print()\n",
        "chat_history_string = str(response[\"chat_history\"]).replace(\"), \", \")§§§ \")[1:-1]\n",
        "chat_history = chat_history_string.split(\"§§§ \")\n",
        "msg_history = []\n",
        "for chat_string in chat_history:\n",
        "  tmp = chat_string.split(\"(content='\")\n",
        "  msg_history.append({\"role\": tmp[0], \"content\": tmp[1][:-2]})\n",
        "for msg in msg_history:\n",
        "  print(msg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EA-3_QJj6tWN",
        "outputId": "69c9fa02-030e-47fd-f626-04a0b363ec25"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"Give me the premium for an insured sum of 10000000 for metal construcion industry\",\n",
            "  \"chat_history\": []\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"Give me the premium for an insured sum of 10000000 for metal construcion industry\",\n",
            "  \"chat_history\": [],\n",
            "  \"intermediate_steps\": []\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableMap] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"Give me the premium for an insured sum of 10000000 for metal construcion industry\",\n",
            "  \"chat_history\": [],\n",
            "  \"intermediate_steps\": []\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableMap > 4:chain:<lambda>] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"Give me the premium for an insured sum of 10000000 for metal construcion industry\",\n",
            "  \"chat_history\": [],\n",
            "  \"intermediate_steps\": []\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableMap > 4:chain:<lambda>] [1ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"Give me the premium for an insured sum of 10000000 for metal construcion industry\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableMap > 5:chain:<lambda>] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"Give me the premium for an insured sum of 10000000 for metal construcion industry\",\n",
            "  \"chat_history\": [],\n",
            "  \"intermediate_steps\": []\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableMap > 5:chain:<lambda>] [1ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": []\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableMap > 6:chain:<lambda>] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"Give me the premium for an insured sum of 10000000 for metal construcion industry\",\n",
            "  \"chat_history\": [],\n",
            "  \"intermediate_steps\": []\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableMap > 6:chain:<lambda>] [0ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": []\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableMap] [11ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"input\": \"Give me the premium for an insured sum of 10000000 for metal construcion industry\",\n",
            "  \"agent_scratchpad\": [],\n",
            "  \"chat_history\": []\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 7:prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"Give me the premium for an insured sum of 10000000 for metal construcion industry\",\n",
            "  \"agent_scratchpad\": [],\n",
            "  \"chat_history\": []\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 7:prompt:ChatPromptTemplate] [6ms] Exiting Prompt run with output:\n",
            "\u001b[0m{\n",
            "  \"lc\": 1,\n",
            "  \"type\": \"constructor\",\n",
            "  \"id\": [\n",
            "    \"langchain\",\n",
            "    \"prompts\",\n",
            "    \"chat\",\n",
            "    \"ChatPromptValue\"\n",
            "  ],\n",
            "  \"kwargs\": {\n",
            "    \"messages\": [\n",
            "      {\n",
            "        \"lc\": 1,\n",
            "        \"type\": \"constructor\",\n",
            "        \"id\": [\n",
            "          \"langchain\",\n",
            "          \"schema\",\n",
            "          \"messages\",\n",
            "          \"SystemMessage\"\n",
            "        ],\n",
            "        \"kwargs\": {\n",
            "          \"content\": \"You are a useful assistant.\",\n",
            "          \"additional_kwargs\": {}\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"lc\": 1,\n",
            "        \"type\": \"constructor\",\n",
            "        \"id\": [\n",
            "          \"langchain\",\n",
            "          \"schema\",\n",
            "          \"messages\",\n",
            "          \"HumanMessage\"\n",
            "        ],\n",
            "        \"kwargs\": {\n",
            "          \"content\": \"Give me the premium for an insured sum of 10000000 for metal construcion industry\",\n",
            "          \"additional_kwargs\": {}\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  }\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 8:llm:ChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"System: You are a useful assistant.\\nHuman: Give me the premium for an insured sum of 10000000 for metal construcion industry\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 8:llm:ChatOpenAI] [2.89s] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"function_call\"\n",
            "        },\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessage\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"\",\n",
            "            \"additional_kwargs\": {\n",
            "              \"function_call\": {\n",
            "                \"name\": \"calculate_insurance_premium\",\n",
            "                \"arguments\": \"{\\n  \\\"insured_sum\\\": 10000000,\\n  \\\"industry\\\": \\\"metal construction\\\"\\n}\"\n",
            "              }\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": {\n",
            "    \"token_usage\": {\n",
            "      \"prompt_tokens\": 109,\n",
            "      \"completion_tokens\": 30,\n",
            "      \"total_tokens\": 139\n",
            "    },\n",
            "    \"model_name\": \"gpt-4-0613\"\n",
            "  },\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 9:parser:OpenAIFunctionsAgentOutputParser] Entering Parser run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 9:parser:OpenAIFunctionsAgentOutputParser] [1ms] Exiting Parser run with output:\n",
            "\u001b[0m{\n",
            "  \"lc\": 1,\n",
            "  \"type\": \"constructor\",\n",
            "  \"id\": [\n",
            "    \"langchain\",\n",
            "    \"schema\",\n",
            "    \"agent\",\n",
            "    \"AgentActionMessageLog\"\n",
            "  ],\n",
            "  \"kwargs\": {\n",
            "    \"tool\": \"calculate_insurance_premium\",\n",
            "    \"tool_input\": {\n",
            "      \"insured_sum\": 10000000,\n",
            "      \"industry\": \"metal construction\"\n",
            "    },\n",
            "    \"log\": \"\\nInvoking: `calculate_insurance_premium` with `{'insured_sum': 10000000, 'industry': 'metal construction'}`\\n\\n\\n\",\n",
            "    \"message_log\": [\n",
            "      {\n",
            "        \"lc\": 1,\n",
            "        \"type\": \"constructor\",\n",
            "        \"id\": [\n",
            "          \"langchain\",\n",
            "          \"schema\",\n",
            "          \"messages\",\n",
            "          \"AIMessage\"\n",
            "        ],\n",
            "        \"kwargs\": {\n",
            "          \"content\": \"\",\n",
            "          \"additional_kwargs\": {\n",
            "            \"function_call\": {\n",
            "              \"name\": \"calculate_insurance_premium\",\n",
            "              \"arguments\": \"{\\n  \\\"insured_sum\\\": 10000000,\\n  \\\"industry\\\": \\\"metal construction\\\"\\n}\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  }\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence] [2.92s] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:tool:calculate_insurance_premium] Entering Tool run with input:\n",
            "\u001b[0m\"{'insured_sum': 10000000, 'industry': 'metal construction'}\"\n",
            "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:tool:calculate_insurance_premium] [1ms] Exiting Tool run with output:\n",
            "\u001b[0m\"2500000.0\"\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence] Entering Chain run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence > 12:chain:RunnableMap] Entering Chain run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence > 12:chain:RunnableMap > 13:chain:<lambda>] Entering Chain run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence > 12:chain:RunnableMap > 13:chain:<lambda>] [1ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"Give me the premium for an insured sum of 10000000 for metal construcion industry\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence > 12:chain:RunnableMap > 14:chain:<lambda>] Entering Chain run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence > 12:chain:RunnableMap > 14:chain:<lambda>] [1ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": [\n",
            "    {\n",
            "      \"lc\": 1,\n",
            "      \"type\": \"constructor\",\n",
            "      \"id\": [\n",
            "        \"langchain\",\n",
            "        \"schema\",\n",
            "        \"messages\",\n",
            "        \"AIMessage\"\n",
            "      ],\n",
            "      \"kwargs\": {\n",
            "        \"content\": \"\",\n",
            "        \"additional_kwargs\": {\n",
            "          \"function_call\": {\n",
            "            \"name\": \"calculate_insurance_premium\",\n",
            "            \"arguments\": \"{\\n  \\\"insured_sum\\\": 10000000,\\n  \\\"industry\\\": \\\"metal construction\\\"\\n}\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"lc\": 1,\n",
            "      \"type\": \"constructor\",\n",
            "      \"id\": [\n",
            "        \"langchain\",\n",
            "        \"schema\",\n",
            "        \"messages\",\n",
            "        \"FunctionMessage\"\n",
            "      ],\n",
            "      \"kwargs\": {\n",
            "        \"name\": \"calculate_insurance_premium\",\n",
            "        \"content\": \"2500000.0\"\n",
            "      }\n",
            "    }\n",
            "  ]\n",
            "}\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence > 12:chain:RunnableMap > 15:chain:<lambda>] Entering Chain run with input:\n",
            "\u001b[0m[inputs]\n",
            "\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence > 12:chain:RunnableMap > 15:chain:<lambda>] [1ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": []\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence > 12:chain:RunnableMap] [8ms] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence > 16:prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence > 16:prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
            "\u001b[0m{\n",
            "  \"lc\": 1,\n",
            "  \"type\": \"constructor\",\n",
            "  \"id\": [\n",
            "    \"langchain\",\n",
            "    \"prompts\",\n",
            "    \"chat\",\n",
            "    \"ChatPromptValue\"\n",
            "  ],\n",
            "  \"kwargs\": {\n",
            "    \"messages\": [\n",
            "      {\n",
            "        \"lc\": 1,\n",
            "        \"type\": \"constructor\",\n",
            "        \"id\": [\n",
            "          \"langchain\",\n",
            "          \"schema\",\n",
            "          \"messages\",\n",
            "          \"SystemMessage\"\n",
            "        ],\n",
            "        \"kwargs\": {\n",
            "          \"content\": \"You are a useful assistant.\",\n",
            "          \"additional_kwargs\": {}\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"lc\": 1,\n",
            "        \"type\": \"constructor\",\n",
            "        \"id\": [\n",
            "          \"langchain\",\n",
            "          \"schema\",\n",
            "          \"messages\",\n",
            "          \"HumanMessage\"\n",
            "        ],\n",
            "        \"kwargs\": {\n",
            "          \"content\": \"Give me the premium for an insured sum of 10000000 for metal construcion industry\",\n",
            "          \"additional_kwargs\": {}\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"lc\": 1,\n",
            "        \"type\": \"constructor\",\n",
            "        \"id\": [\n",
            "          \"langchain\",\n",
            "          \"schema\",\n",
            "          \"messages\",\n",
            "          \"AIMessage\"\n",
            "        ],\n",
            "        \"kwargs\": {\n",
            "          \"content\": \"\",\n",
            "          \"additional_kwargs\": {\n",
            "            \"function_call\": {\n",
            "              \"name\": \"calculate_insurance_premium\",\n",
            "              \"arguments\": \"{\\n  \\\"insured_sum\\\": 10000000,\\n  \\\"industry\\\": \\\"metal construction\\\"\\n}\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"lc\": 1,\n",
            "        \"type\": \"constructor\",\n",
            "        \"id\": [\n",
            "          \"langchain\",\n",
            "          \"schema\",\n",
            "          \"messages\",\n",
            "          \"FunctionMessage\"\n",
            "        ],\n",
            "        \"kwargs\": {\n",
            "          \"name\": \"calculate_insurance_premium\",\n",
            "          \"content\": \"2500000.0\"\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  }\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence > 17:llm:ChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"System: You are a useful assistant.\\nHuman: Give me the premium for an insured sum of 10000000 for metal construcion industry\\nAI: {'name': 'calculate_insurance_premium', 'arguments': '{\\\\n  \\\"insured_sum\\\": 10000000,\\\\n  \\\"industry\\\": \\\"metal construction\\\"\\\\n}'}\\nFunction: 2500000.0\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence > 17:llm:ChatOpenAI] [2.32s] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"The premium for an insured sum of 10,000,000 in the metal construction industry is 2,500,000.\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\"\n",
            "        },\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessage\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"The premium for an insured sum of 10,000,000 in the metal construction industry is 2,500,000.\",\n",
            "            \"additional_kwargs\": {}\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": {\n",
            "    \"token_usage\": {\n",
            "      \"prompt_tokens\": 155,\n",
            "      \"completion_tokens\": 27,\n",
            "      \"total_tokens\": 182\n",
            "    },\n",
            "    \"model_name\": \"gpt-4-0613\"\n",
            "  },\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence > 18:parser:OpenAIFunctionsAgentOutputParser] Entering Parser run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence > 18:parser:OpenAIFunctionsAgentOutputParser] [1ms] Exiting Parser run with output:\n",
            "\u001b[0m{\n",
            "  \"lc\": 1,\n",
            "  \"type\": \"constructor\",\n",
            "  \"id\": [\n",
            "    \"langchain\",\n",
            "    \"schema\",\n",
            "    \"agent\",\n",
            "    \"AgentFinish\"\n",
            "  ],\n",
            "  \"kwargs\": {\n",
            "    \"return_values\": {\n",
            "      \"output\": \"The premium for an insured sum of 10,000,000 in the metal construction industry is 2,500,000.\"\n",
            "    },\n",
            "    \"log\": \"The premium for an insured sum of 10,000,000 in the metal construction industry is 2,500,000.\"\n",
            "  }\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence] [2.33s] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor] [5.26s] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"The premium for an insured sum of 10,000,000 in the metal construction industry is 2,500,000.\"\n",
            "}\n",
            "\n",
            "Give me the premium for an insured sum of 10000000 for metal construcion\n",
            "industry\n",
            "\n",
            "The premium for an insured sum of 10,000,000 in the metal construction industry\n",
            "is 2,500,000.\n",
            "\n",
            "{'role': 'HumanMessage', 'content': 'Give me the premium for an insured sum of 10000000 for metal construcion industry'}\n",
            "{'role': 'AIMessage', 'content': 'The premium for an insured sum of 10,000,000 in the metal construction industry is 2,500,000.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(textwrap.fill(str(response[\"input\"]), 80))\n",
        "print()\n",
        "print(textwrap.fill(str(response[\"output\"]), 80))\n",
        "print()\n",
        "chat_history_string = str(response[\"chat_history\"]).replace(\"), \", \")§§§ \")[1:-1]\n",
        "chat_history = chat_history_string.split(\"§§§ \")\n",
        "msg_history = []\n",
        "for chat_string in chat_history:\n",
        "  tmp = chat_string.split(\"(content='\")\n",
        "  msg_history.append({\"role\": tmp[0], \"content\": tmp[1][:-2]})\n",
        "for msg in msg_history:\n",
        "  print(msg)"
      ],
      "metadata": {
        "id": "9Zsnvgf6BRaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CLI for Agent (Chatbot with memory)"
      ],
      "metadata": {
        "id": "-fL3b1FXIx9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, memory=memory)\n",
        "messages = [{\"role\": \"assistant\", \"content\": \"How can I help you?\"}]"
      ],
      "metadata": {
        "id": "qVfrjxhuUbn9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prompt = \"Give me the premium for an insured sum of 10000000\"\n",
        "prompt = \"The industry is chemical production\"\n",
        "#prompt = \"And the temperature in Celsius?\"\n",
        "messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "print(\"user: \" + prompt)\n",
        "response = agent_executor.invoke({\"input\": prompt})\n",
        "msg = {\"role\": \"assistant\", \"content\": response[\"output\"]}\n",
        "messages.append(msg)\n",
        "print(textwrap.fill(\"assistant: \" + response[\"output\"], 80))\n",
        "print(\"\\nHistory:\")\n",
        "for msg in messages:\n",
        "    #st.chat_message(msg[\"role\"]).write(msg[\"content\"])\n",
        "    print(textwrap.fill(msg[\"role\"] + \": \" + msg[\"content\"], 80))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjDvg8GSaSP8",
        "outputId": "2736f84b-0630-4fac-cc9f-7e3e75901922"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user: The industry is chemical production\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `calculate_insurance_premium` with `{'insured_sum': 10000000, 'industry': 'chemical production'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m2500000.0\u001b[0m\u001b[32;1m\u001b[1;3mThe premium for an insured sum of 10,000,000 in the chemical production industry is 2,500,000.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "assistant: The premium for an insured sum of 10,000,000 in the chemical\n",
            "production industry is 2,500,000.\n",
            "\n",
            "History:\n",
            "assistant: How can I help you?\n",
            "user: Give me the premium for an insured sum of 10000000\n",
            "assistant: Sure, I can help with that. However, I also need to know the industry\n",
            "of the customer to calculate the insurance premium. Could you please provide\n",
            "that information?\n",
            "user: The industry is chemical production\n",
            "assistant: The premium for an insured sum of 10,000,000 in the chemical\n",
            "production industry is 2,500,000.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Memory from response object:\")\n",
        "chat_history_string = str(response[\"chat_history\"]).replace(\"), \", \")§§§ \")[1:-1]\n",
        "chat_history = chat_history_string.split(\"§§§ \")\n",
        "msg_history = []\n",
        "for chat_string in chat_history:\n",
        "  tmp = chat_string.split(\"(content='\")\n",
        "  msg_history.append({\"role\": tmp[0], \"content\": tmp[1][:-2]})\n",
        "for msg in msg_history:\n",
        "  print(msg)"
      ],
      "metadata": {
        "id": "ZmCuWwuijWDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Work in progress..."
      ],
      "metadata": {
        "id": "ZQ02m2ARb8cO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"LANGCHAIN_TRACING\"] = \"true\"\n",
        "llm = ChatOpenAI(temperature=0, model='gpt-4-0613')"
      ],
      "metadata": {
        "id": "Zs1dGiVGcmtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tool 1\n",
        "def multiplier(a: float, b: float) -> float:\n",
        "    \"\"\"Multiply the provided floats.\"\"\"\n",
        "    return a * b\n",
        "\n",
        "tool = StructuredTool.from_function(multiplier)\n",
        "\n",
        "agent_executor = initialize_agent(\n",
        "    [tool],\n",
        "    llm,\n",
        "    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True,\n",
        ")\n",
        "prompt = \"What is 3 times 4\"\n",
        "response_text = agent_executor.run(prompt)\n",
        "print(response_text)\n",
        "response = agent_executor.invoke({\"input\": prompt})\n",
        "#print(textwrap.fill(str(response[\"output\"]), 80))\n"
      ],
      "metadata": {
        "id": "LtfgVAjZc14k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tool 2\n",
        "def calculate_insurance_premium(insured_sum: int, industry: str) -> float:\n",
        "    \"\"\"Calculate the premium for an insurance based on the maximum insured sum and the industry of the customer.\"\"\"\n",
        "    premium = insured_sum*0.25\n",
        "    return premium\n",
        "\n",
        "tool = StructuredTool.from_function(calculate_insurance_premium, return_direct=False)\n",
        "\n",
        "agent_executor = initialize_agent(\n",
        "    [tool],\n",
        "    llm,\n",
        "    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "prompt = \"Give me the premium for an insured sum of 10000000\"\n",
        "prompt = \"Kalkuliere die Versicherungsprämie für eine Versicherungssumme von 10000000, die Branche ist Metallbau\"\n",
        "response_text = agent_executor.run(prompt)\n",
        "print(response_text)\n",
        "response = agent_executor.invoke({\"input\": prompt})\n",
        "#print(textwrap.fill(str(response[\"output\"]), 80))\n"
      ],
      "metadata": {
        "id": "dF2g6iTCdM0P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
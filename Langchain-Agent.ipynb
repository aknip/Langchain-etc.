{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQlHYot0Yc4ZtNuMqsw9BW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aknip/Langchain-etc./blob/main/Langchain-Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Langchain Agent\n",
        "\n",
        "1. Run cells \"Setup for all agents and apps\"\n",
        "2. Run one of the Agent sections / cells\n",
        "3. Run Gradio app or CLI apps\n"
      ],
      "metadata": {
        "id": "_yJpe7D-EXzF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup for all agents and apps"
      ],
      "metadata": {
        "id": "gOMfnUf3_oTj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import psutil\n",
        "IN_NOTEBOOK = any([\"jupyter-notebook\" in i for i in psutil.Process().parent().cmdline()])"
      ],
      "metadata": {
        "id": "K_sEe-A1S56l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afIkZ1hD4RYB"
      },
      "outputs": [],
      "source": [
        "!pip install langchain langchainhub langchain_experimental google-search-results wikipedia openai gradio -q\n",
        "# !pip install google-search-results wikipedia -q\n",
        "%load_ext gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "from getpass import getpass\n",
        "if IN_NOTEBOOK:\n",
        "  CREDS = json.loads(getpass(\"Secrets (JSON string): \"))\n",
        "  os.environ['CREDS'] = json.dumps(CREDS)\n",
        "  CREDS = json.loads(os.getenv('CREDS'))"
      ],
      "metadata": {
        "id": "IWrCvpKaENeu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import Tool, AgentExecutor\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain import hub\n",
        "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain.utilities import SerpAPIWrapper, SQLDatabase, WikipediaAPIWrapper\n",
        "from langchain_experimental.sql import SQLDatabaseChain\n",
        "from langchain.tools import WikipediaQueryRun\n",
        "from langchain.agents.format_scratchpad import format_to_openai_functions\n",
        "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
        "from langchain.tools.render import format_tool_to_openai_function\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain.tools import BaseTool, StructuredTool\n",
        "from langchain.schema.agent import AgentFinish\n",
        "import os\n",
        "import langchain\n",
        "import openai\n",
        "import textwrap\n",
        "import gradio as gr\n",
        "import random\n",
        "import time"
      ],
      "metadata": {
        "id": "CEhw8Ye15BgC"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agent 1: Wikpedia, Search, Music DB"
      ],
      "metadata": {
        "id": "eHa5SgMbz5fa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download \"Chinook\" Music Sales DB\n",
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "fname = 'chinook.zip'\n",
        "url = 'https://www.sqlitetutorial.net/wp-content/uploads/2018/03/' + fname\n",
        "r = requests.get(url)\n",
        "open(fname, 'wb').write(r.content)\n",
        "zipfile.ZipFile('chinook.zip').extractall()\n",
        "assert os.path.exists('chinook.db')"
      ],
      "metadata": {
        "id": "NE6D9WvpGL1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = CREDS['OpenAI']['v2']['credential']\n",
        "llm = ChatOpenAI(temperature=0, model='gpt-4-0613')\n",
        "search = SerpAPIWrapper(serpapi_api_key=CREDS['SERP-API']['key']['credential'])\n",
        "db = SQLDatabase.from_uri(\"sqlite:///chinook.db\")\n",
        "db_chain = SQLDatabaseChain.from_llm(llm, db, verbose=True)\n",
        "wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
        "tools = [\n",
        "    Tool(\n",
        "        name = \"Search\",\n",
        "        func=search.run,\n",
        "        description=\"useful for when you need to answer questions about real-time events. You should ask targeted questions\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"Wikipedia\",\n",
        "        func=wikipedia.run,\n",
        "        description=\"useful for when you need to answer questions about a big picture or background of something.\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"MusicSales\",\n",
        "        func=db_chain.run,\n",
        "        description=\"useful for when you need to answer questions about mucis sales in a store. Should be strickly follow the tables info.\"\n",
        "    )\n",
        "]\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a useful assistant.\"),\n",
        "    MessagesPlaceholder(variable_name='chat_history'),\n",
        "    (\"user\", \"{input}\"),\n",
        "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "])\n",
        "\n",
        "llm_with_tools = llm.bind(\n",
        "    functions=[format_tool_to_openai_function(t) for t in tools]\n",
        ")\n",
        "\n",
        "agent = {\n",
        "    \"input\": lambda x: x[\"input\"],\n",
        "    \"agent_scratchpad\": lambda x: format_to_openai_functions(x['intermediate_steps']),\n",
        "    \"chat_history\": lambda x: x[\"chat_history\"]\n",
        "} | prompt | llm_with_tools | OpenAIFunctionsAgentOutputParser()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HcePPP4M5HPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agent 2: Calculate insurance premium"
      ],
      "metadata": {
        "id": "EoYqbRg0_w19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = CREDS['OpenAI']['v2']['credential']\n",
        "llm = ChatOpenAI(temperature=0, model='gpt-4-0613')\n",
        "\n",
        "def calculate_insurance_premium(insured_sum: int, industry: str) -> float:\n",
        "    \"\"\"Calculate the premium for an insurance based on the maximum insured sum and the industry of the customer.\"\"\"\n",
        "    premium = insured_sum*0.25\n",
        "    return premium\n",
        "\n",
        "calculation_tool = StructuredTool.from_function(calculate_insurance_premium, return_direct=False) # True return result without additional text\n",
        "\n",
        "tools = [\n",
        "    calculation_tool\n",
        "]\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a useful assistant.\"),\n",
        "    MessagesPlaceholder(variable_name='chat_history'),\n",
        "    (\"user\", \"{input}\"),\n",
        "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "])\n",
        "\n",
        "llm_with_tools = llm.bind(\n",
        "    functions=[format_tool_to_openai_function(t) for t in tools]\n",
        ")\n",
        "\n",
        "agent = {\n",
        "    \"input\": lambda x: x[\"input\"],\n",
        "    \"agent_scratchpad\": lambda x: format_to_openai_functions(x['intermediate_steps']),\n",
        "    \"chat_history\": lambda x: x[\"chat_history\"]\n",
        "} | prompt | llm_with_tools | OpenAIFunctionsAgentOutputParser()\n"
      ],
      "metadata": {
        "id": "vAzSbqz7_0_U"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradio Chat App for Agent"
      ],
      "metadata": {
        "id": "O_jGi0yQ-sEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, memory=memory)\n",
        "\n",
        "#\n",
        "# Gradio app\n",
        "#\n",
        "\n",
        "# Theming\n",
        "theme = gr.themes.Default(\n",
        "    primary_hue=\"slate\" # , radius_size=gr.themes.Size(radius_sm=\"3px\", radius_xs=\"2px\", radius_xxs=\"1px\")\n",
        ")\n",
        "# Styling: Change max width\n",
        "css = \"\"\"\n",
        "  .gradio-container {max-width: 800px!important}\n",
        "  .vspacer1 {margin-top: 20px}\n",
        "\"\"\"\n",
        "\n",
        "with gr.Blocks(theme=theme, css=css) as demo:\n",
        "\n",
        "    gr.Markdown(\"# Agent Chat\", elem_classes=\"vspacer1\")\n",
        "\n",
        "    with gr.Tab(\"Chat\"):\n",
        "      # https://www.gradio.app/docs/chatbot\n",
        "\n",
        "      chatbot = gr.Chatbot(bubble_full_width=False)\n",
        "      msg = gr.Textbox()\n",
        "      clear = gr.ClearButton([msg, chatbot])\n",
        "\n",
        "      # Init agent and memory\n",
        "      memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "      agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, memory=memory)\n",
        "      messages = [{\"role\": \"assistant\", \"content\": \"How can I help you?\"}]\n",
        "      #chatbot.append(None, \"How can I help you?\")\n",
        "\n",
        "      def ask(message, chat_history):\n",
        "          chat_history.append((message, None))\n",
        "          messages.append({\"role\": \"user\", \"content\": message})\n",
        "          return \"\", chat_history\n",
        "\n",
        "      def respond(chat_history):\n",
        "          prompt = chat_history[-1][0] # get prompt from history (last entry)\n",
        "          response = agent_executor.invoke({\"input\": prompt})\n",
        "          msg = {\"role\": \"assistant\", \"content\": response[\"output\"]}\n",
        "          messages.append(msg)\n",
        "          chat_history.append((None, response[\"output\"]))\n",
        "          print(\"\\n\\nMemory from response object:\")\n",
        "          print(textwrap.fill(str(response[\"chat_history\"]), 80))\n",
        "          return chat_history\n",
        "\n",
        "      msg.submit(ask, [msg, chatbot], [msg, chatbot], queue=False).then(\n",
        "        respond, chatbot, chatbot\n",
        "      )\n",
        "\n",
        "demo.launch(quiet=True, share=False, debug=True)"
      ],
      "metadata": {
        "id": "kioXkMb2-vUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CLI für agent_executor (Single Prompt)"
      ],
      "metadata": {
        "id": "dij8ZZWdbC5k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=False,  memory=memory)\n",
        "\n",
        "langchain.debug = False\n",
        "\n",
        "prompt = \"Give me the premium for an insured sum of 10000000 for metal construcion industry\"\n",
        "# prompt = \"Wie viele Menschen leben in den USA?\"\n",
        "# prompt = \"How many people live in the US?\"\n",
        "# prompt = \"What is the best selling song in the music store?\"\n",
        "# prompt = \"What is the cheapest album in the music store? Tell me the price.\"\n",
        "# prompt = \"What is the best selling song starting with the letter 'F' in the music store? Tell me title and artist.\"\n",
        "# prompt = \"How is the weather now in Cologne? Please use Celsius as unit for temperature.\"\n",
        "response = agent_executor.invoke({\"input\": prompt})\n",
        "\n",
        "# Response-Objekte:\n",
        "print()\n",
        "print(textwrap.fill(str(response[\"input\"]), 80))\n",
        "print()\n",
        "print(textwrap.fill(str(response[\"output\"]), 80))\n",
        "print()\n",
        "chat_history_string = str(response[\"chat_history\"]).replace(\"), \", \")§§§ \")[1:-1]\n",
        "chat_history = chat_history_string.split(\"§§§ \")\n",
        "msg_history = []\n",
        "for chat_string in chat_history:\n",
        "  tmp = chat_string.split(\"(content='\")\n",
        "  msg_history.append({\"role\": tmp[0], \"content\": tmp[1][:-2]})\n",
        "for msg in msg_history:\n",
        "  print(msg)"
      ],
      "metadata": {
        "id": "EA-3_QJj6tWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(textwrap.fill(str(response[\"input\"]), 80))\n",
        "print()\n",
        "print(textwrap.fill(str(response[\"output\"]), 80))\n",
        "print()\n",
        "chat_history_string = str(response[\"chat_history\"]).replace(\"), \", \")§§§ \")[1:-1]\n",
        "chat_history = chat_history_string.split(\"§§§ \")\n",
        "msg_history = []\n",
        "for chat_string in chat_history:\n",
        "  tmp = chat_string.split(\"(content='\")\n",
        "  msg_history.append({\"role\": tmp[0], \"content\": tmp[1][:-2]})\n",
        "for msg in msg_history:\n",
        "  print(msg)"
      ],
      "metadata": {
        "id": "9Zsnvgf6BRaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CLI for agent_executor (Chatbot with memory)"
      ],
      "metadata": {
        "id": "-fL3b1FXIx9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, memory=memory)\n",
        "messages = [{\"role\": \"assistant\", \"content\": \"How can I help you?\"}]\n",
        "langchain.debug = False"
      ],
      "metadata": {
        "id": "qVfrjxhuUbn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prompt = \"Give me the premium for an insured sum of 10000000\"\n",
        "prompt = \"The industry is chemical production\"\n",
        "#prompt = \"And the temperature in Celsius?\"\n",
        "messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "print(\"user: \" + prompt)\n",
        "response = agent_executor.invoke({\"input\": prompt})\n",
        "msg = {\"role\": \"assistant\", \"content\": response[\"output\"]}\n",
        "messages.append(msg)\n",
        "print(textwrap.fill(\"assistant: \" + response[\"output\"], 80))\n",
        "print(\"\\nHistory:\")\n",
        "for msg in messages:\n",
        "    #st.chat_message(msg[\"role\"]).write(msg[\"content\"])\n",
        "    print(textwrap.fill(msg[\"role\"] + \": \" + msg[\"content\"], 80))"
      ],
      "metadata": {
        "id": "OjDvg8GSaSP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Memory from response object:\")\n",
        "chat_history_string = str(response[\"chat_history\"]).replace(\"), \", \")§§§ \")[1:-1]\n",
        "chat_history = chat_history_string.split(\"§§§ \")\n",
        "msg_history = []\n",
        "for chat_string in chat_history:\n",
        "  tmp = chat_string.split(\"(content='\")\n",
        "  msg_history.append({\"role\": tmp[0], \"content\": tmp[1][:-2]})\n",
        "for msg in msg_history:\n",
        "  print(msg)"
      ],
      "metadata": {
        "id": "ZmCuWwuijWDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CLI for agent (Chatbot with memory)"
      ],
      "metadata": {
        "id": "dnhhXmq0sYVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent_kwargs = {\n",
        "    \"extra_prompt_messages\": [MessagesPlaceholder(variable_name=\"chat_history\")],\n",
        "}\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "agent = initialize_agent(\n",
        "    tools,\n",
        "    llm,\n",
        "    agent=AgentType.OPENAI_FUNCTIONS,\n",
        "    verbose=False,\n",
        "    agent_kwargs=agent_kwargs,\n",
        "    memory=memory,\n",
        ")\n",
        "langchain.debug = False"
      ],
      "metadata": {
        "id": "Xs3oopFVsdXy"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\"hi\")\n",
        "agent.run(\"My name is Bob\")\n",
        "agent.run(\"Wie lautet mein Name?\")\n",
        "agent.run(\"Give me the premium for an insured sum of 10000000.\")\n",
        "agent.run(\"it is metal construction industry\")"
      ],
      "metadata": {
        "id": "lKxJyc-CskpC",
        "outputId": "18592e81-4e57-48c4-96b8-93bd51bd092d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The premium for an insured sum of 10,000,000 in the metal construction industry is 2,500,000.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Work in progress..."
      ],
      "metadata": {
        "id": "ZQ02m2ARb8cO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"LANGCHAIN_TRACING\"] = \"true\"\n",
        "llm = ChatOpenAI(temperature=0, model='gpt-4-0613')"
      ],
      "metadata": {
        "id": "Zs1dGiVGcmtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tool 1\n",
        "def multiplier(a: float, b: float) -> float:\n",
        "    \"\"\"Multiply the provided floats.\"\"\"\n",
        "    return a * b\n",
        "\n",
        "tool = StructuredTool.from_function(multiplier)\n",
        "\n",
        "agent_executor = initialize_agent(\n",
        "    [tool],\n",
        "    llm,\n",
        "    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True,\n",
        ")\n",
        "# The one Agent than can accept a structured tool with multiple arguments is the STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION Agent type\n",
        "# add memory: https://python.langchain.com/docs/modules/agents/agent_types/structured_chat#adding-in-memory\n",
        "\n",
        "prompt = \"What is 3 times 4\"\n",
        "response_text = agent_executor.run(prompt)\n",
        "print(response_text)\n",
        "response = agent_executor.invoke({\"input\": prompt})\n",
        "#print(textwrap.fill(str(response[\"output\"]), 80))\n"
      ],
      "metadata": {
        "id": "LtfgVAjZc14k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tool 2\n",
        "def calculate_insurance_premium(insured_sum: int, industry: str) -> float:\n",
        "    \"\"\"Calculate the premium for an insurance based on the maximum insured sum and the industry of the customer.\"\"\"\n",
        "    premium = insured_sum*0.25\n",
        "    return premium\n",
        "\n",
        "tool = StructuredTool.from_function(calculate_insurance_premium, return_direct=False)\n",
        "\n",
        "agent_executor = initialize_agent(\n",
        "    [tool],\n",
        "    llm,\n",
        "    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "prompt = \"Give me the premium for an insured sum of 10000000\"\n",
        "prompt = \"Kalkuliere die Versicherungsprämie für eine Versicherungssumme von 10000000, die Branche ist Metallbau\"\n",
        "response_text = agent_executor.run(prompt)\n",
        "print(response_text)\n",
        "response = agent_executor.invoke({\"input\": prompt})\n",
        "#print(textwrap.fill(str(response[\"output\"]), 80))\n"
      ],
      "metadata": {
        "id": "dF2g6iTCdM0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Manual loop for agent_executor"
      ],
      "metadata": {
        "id": "CS2Q0VjjxpIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# see https://levelup.gitconnected.com/building-a-powerful-agent-has-no-challenge-today-774e27be818d\n",
        "\n",
        "# only for single prompt - no memory !\n",
        "\n",
        "llm = ChatOpenAI(temperature=0, model='gpt-4-0613')\n",
        "\n",
        "from langchain.agents import tool\n",
        "\n",
        "@tool\n",
        "def get_word_length(word: str) -> int:\n",
        "    \"\"\"Returns the length of a word.\"\"\"\n",
        "    return len(word)\n",
        "\n",
        "tools = [get_word_length]\n",
        "tools_dict = {\"get_word_length\": get_word_length}\n",
        "\n",
        "llm_with_tools = llm.bind(\n",
        "    functions=[format_tool_to_openai_function(t) for t in tools]\n",
        ")\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a useful assistant.\"),\n",
        "    (\"user\", \"{input}\"),\n",
        "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "])\n",
        "\n",
        "agent = {\n",
        "    \"input\": lambda x: x[\"input\"],\n",
        "    \"agent_scratchpad\": lambda x: format_to_openai_functions(x['intermediate_steps'])\n",
        "} | prompt | llm_with_tools | OpenAIFunctionsAgentOutputParser()\n",
        "\n",
        "langchain.debug = False\n",
        "\n",
        "intermediate_steps = []\n",
        "while True:\n",
        "    output = agent.invoke({\n",
        "        \"input\": \"how many letters in the word educa?\",\n",
        "        \"intermediate_steps\": intermediate_steps\n",
        "    })\n",
        "    if isinstance(output, AgentFinish):\n",
        "        final_result = output.return_values[\"output\"]\n",
        "        break\n",
        "    else:\n",
        "        print(output.tool, output.tool_input)\n",
        "        #tool = {\n",
        "        #    \"get_word_length\": get_word_length\n",
        "        #}[output.tool]\n",
        "        tool = tools_dict[output.tool]\n",
        "        observation = tool.run(output.tool_input)\n",
        "        intermediate_steps.append((output, observation))\n",
        "print(final_result)"
      ],
      "metadata": {
        "id": "bDxK3olHt70e",
        "outputId": "85c85a7d-e10a-463b-b405-1f5aceee1002",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "get_word_length {'word': 'educa'}\n",
            "The word \"educa\" has 5 letters.\n"
          ]
        }
      ]
    }
  ]
}